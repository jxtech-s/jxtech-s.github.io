<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-29T12:55:48+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">JXTech</title><subtitle>Advanced probability problems and detailed solutions</subtitle><author><name>JXTech</name></author><entry><title type="html">Modified RNG</title><link href="http://localhost:4000/probability/problems/2025/03/29/Modified-RNG.html" rel="alternate" type="text/html" title="Modified RNG" /><published>2025-03-29T00:00:00+05:30</published><updated>2025-03-29T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/29/Modified-RNG</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/29/Modified-RNG.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>Jimmy picks a number uniformly at random from (0,1). If Jimmy chooses x, then Jon picks a number from (x,1) uniformly at random. If Y represents the number Jon selects, in simplest form, find \(\frac{\mathbb{E}[Y]}{Var(Y)}\)</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/modified-rng">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1---compute-conditional-expectation-mathbbey-mid-x-and-conditional-variance-vary-mid-x">Step 1 - Compute Conditional Expectation \(\mathbb{E}[Y \mid X]\) and Conditional Variance \(Var(Y \mid X)\)</h3>

<p>For \(Y\) uniform on \((X,1)\), the conditional expectation is:</p>

\[\mathbb{E}[Y \mid X] = \frac{X+1}{2}\]

<p>How? Its obvious that its gonna be the middle point! Alternatively, you can integrate and compute using the standard method.</p>

<p>Similarly, for Conditional Variance \(Var[Y \mid X]\), we have</p>

\[Var[Y \mid X] = \frac{(1-X)^2}{12}\]

<h3 id="step-2---total-expectation">Step 2 - Total Expectation</h3>

<p>Using the law of total expectation:</p>

\[\mathbb{E}[Y] = \mathbb{E}[\mathbb{E}[Y \mid X]] = \mathbb{E}\left[\frac{X+1}{2}\right] = \int_0^1 \frac{x+1}{2} dx = \left[\frac{x^2}{4} + \frac{x}{2}\right]_0^1 = \frac{1}{4} + \frac{1}{2} = \frac{3}{4}\]

<h3 id="step-3---computing-total-variance">Step 3 - Computing Total Variance</h3>

<p>Using the law of total variance:</p>

\[Var(Y) = \mathbb{E}[Var(Y \mid X)] + Var(\mathbb{E}[Y \mid X])\]

<p>First, compute \(\mathbb{E}[Var(Y \mid X)]\):</p>

\[\mathbb{E}[Var(Y \mid X)] = \int_0^1 \frac{(1-x)^2}{12} dx\]

\[= \frac{1}{12} \int_0^1 (1-x)^2 dx = \frac{1}{12} \left[\frac{-1}{3}(1-x)^3\right]_0^1 = \frac{1}{12} \cdot \frac{1}{3} = \frac{1}{36}\]

<p>Next, compute \(Var(\mathbb{E}[Y \mid X])\):</p>

\[Var(\mathbb{E}[Y \mid X]) = \mathbb{E}\left[\left(\frac{X+1}{2}\right)^2\right] - \left(\mathbb{E}\left[\frac{X+1}{2}\right]\right)^2\]

\[= \int_0^1 \frac{(x+1)^2}{4} dx - \left(\frac{3}{4}\right)^2 = \frac{1}{4} \int_0^1 (x^2 + 2x + 1) dx - \frac{9}{16}\]

\[= \frac{1}{4} \left[\frac{x^3}{3} + x^2 + x\right]_0^1 - \frac{9}{16} = \frac{1}{4} \left(\frac{1}{3} + 1 + 1\right) - \frac{9}{16} = \frac{1}{4} \cdot \frac{7}{3} - \frac{9}{16} = \frac{7}{12} - \frac{9}{16} = \frac{1}{48}\]

<p>Therefore:</p>

\[Var(Y) = \frac{1}{36} + \frac{1}{48} = \frac{7}{144}\]

<h3 id="final-answer">Final Answer</h3>

\[\frac{\mathbb{E}[Y]}{Var(Y)} = \frac{3/4}{7/144} = \frac{108}{7}\]

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><category term="Conditional Expectation" /><category term="Conditional Variance" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Russian Roulette II</title><link href="http://localhost:4000/probability/problems/2025/03/29/Russian-Roulette-II.html" rel="alternate" type="text/html" title="Russian Roulette II" /><published>2025-03-29T00:00:00+05:30</published><updated>2025-03-29T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/29/Russian-Roulette-II</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/29/Russian-Roulette-II.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You’re playing a game of Russian Roulette with a friend. The six-chambered revolver is loaded with one bullet. Initially, the cylinder is spun to randomize the order of the chambers. The two of you take turns pulling the trigger until the person who fires the gun loses. Given that the cylinder is re-spun after each turn, what is the probability that you win if your friend goes first?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/russian-roulette-ii">Click here</a><br />
<strong>First version</strong>: <a href="https://jxtech-s.github.io/probability/problems/2025/03/29/Russian-Roulette-I.html">Russian Roulette I</a></p>

<hr />

<h2 id="solution">Solution</h2>

<h3 id="step-1-understanding-the-difference">Step 1: Understanding the Difference</h3>

<p>Unlike the previous version, the key difference here is that after each turn, the cylinder is re-spun. This means:</p>
<ul>
  <li>Every turn is independent of the previous turns.</li>
  <li>At every turn, the probability of firing the bullet remains constant.</li>
</ul>

<p>Since the chamber is re-randomized, on each turn, the probability that the player firing will shoot the chamber with the bullet is:</p>

\[\frac{1}{6}\]

<p>Similarly, the probability that the bullet is not fired on any given turn is:</p>

\[\frac{5}{6}\]

<h3 id="step-2-analyzing-the-winning-chances">Step 2: Analyzing the Winning Chances</h3>

<p>For you to win, the game must end on an odd-numbered turn (i.e., your friend fires and survives, then you fire and lose).</p>

<ul>
  <li>Case 1: Your friend loses immediately (turn 1).
    <ul>
      <li>Probability = \(\frac{1}{6}\).</li>
    </ul>
  </li>
  <li>Case 2: Your friend survives, you survive, then your friend loses (turn 3).
    <ul>
      <li>Probability = \(\left(\frac{5}{6}\right) \times \left(\frac{5}{6}\right) \times \frac{1}{6}\).</li>
    </ul>
  </li>
  <li>Case 3: Your friend survives, you survive, your friend survives, you survive, then your friend loses (turn 5).
    <ul>
      <li>Probability = \(\left(\frac{5}{6}\right)^2 \times \left(\frac{5}{6}\right)^2 \times \frac{1}{6}\).</li>
    </ul>
  </li>
</ul>

<p>Generalizing, the probability that your friend loses on the 2(k-1)th turn is (factor of 2 as we will win only in the odd numbered cases) -</p>

\[\left(\frac{5}{6}\right)^{2(k-1)} \times \frac{1}{6}\]

<p>Summing this up for all \(k\):</p>

\[P(\text{You win}) = \sum_{k=1}^{\infty} \left(\frac{5}{6}\right)^{2(k-1)} \times \frac{1}{6}\]

<h3 id="step-3-summing-the-infinite-geometric-series">Step 3: Summing the Infinite Geometric Series</h3>

<p>This is a geometric series with first term:</p>

\[a = \frac{1}{6}\]

<p>and common ratio:</p>

\[r = \left(\frac{5}{6}\right)^2 = \frac{25}{36}\]

<p>Using the sum formula for an infinite geometric series:</p>

\[S = \frac{a}{1 - r}\]

<p>we get:</p>

\[P(\text{You win}) = \frac{\frac{1}{6}}{1 - \frac{25}{36}}\]

\[= \frac{\frac{1}{6}}{\frac{11}{36}}\]

\[= \frac{1}{6} \times \frac{36}{11} = \frac{6}{11}\]

<h3 id="thus-the-probability-that-we-will-win-is-frac611">Thus, the probability that we will win is \(\frac{6}{11}\)</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Probability" /><category term="Series" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Russian Roulette I</title><link href="http://localhost:4000/probability/problems/2025/03/29/Russian-Roulette-I.html" rel="alternate" type="text/html" title="Russian Roulette I" /><published>2025-03-29T00:00:00+05:30</published><updated>2025-03-29T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/29/Russian-Roulette-I</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/29/Russian-Roulette-I.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You’re playing a game of Russian Roulette with a friend. The six-chambered revolver is loaded with one bullet. Initially, the cylinder is spun to randomize the order of the chambers. The two of you take turns pulling the trigger until the person who fires the gun loses. Given that the cylinder is not re-spun after each turn, what is the probability that you win if your friend goes first?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/russian-roulette-i">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1-understanding-the-setup">Step 1: Understanding the Setup</h3>

<p>The revolver has 6 chambers, and exactly one of them contains a bullet. Since the cylinder is spun at the start, the bullet is equally likely to be in any of the 6 positions.</p>

<p>The game proceeds in turns:</p>
<ul>
  <li>Your friend goes first.</li>
  <li>If the bullet is in the chamber they fire, they lose immediately.</li>
  <li>Otherwise, the turn passes to you.</li>
  <li>The game continues until someone loses.</li>
</ul>

<h3 id="step-2-analyzing-possible-bullet-positions">Step 2: Analyzing Possible Bullet Positions</h3>

<p>Let’s label the chambers \(1\) to \(6\), where \(1\) is the chamber fired first, \(2\) is fired second, and so on.</p>

<ul>
  <li>If the bullet is in chamber \(1\), your friend loses immediately.</li>
  <li>If the bullet is in chamber \(2\), you lose immediately.</li>
  <li>If the bullet is in chamber \(3\), your friend fires an empty chamber, then you fire an empty chamber, then your friend fires chamber \(3\) and loses.</li>
  <li>If the bullet is in chamber \(4\), you lose (similar reasoning).</li>
  <li>If the bullet is in chamber \(5\), your friend loses.</li>
  <li>If the bullet is in chamber \(6\), you lose.</li>
</ul>

<p>Thus, we win if the bullet is in chambers \(1\), \(3\) or \(5\).</p>

<h3 id="step-3-computing-the-probability">Step 3: Computing the Probability</h3>

<p>Since each chamber is equally likely to contain the bullet, the probability of each case is:</p>

\[\mathbb{P}(\text{Bullet in chamber } i) = \frac{1}{6}\]

<p>From our analysis, we win in 3 out of the 6 cases (chambers \(1\), \(3\) and \(5\)).</p>

<p>Thus, the probability of winning is:</p>

\[\frac{3}{6} = \frac{1}{2}\]

<h3 id="thus-the-probability-that-we-will-win-is-frac12">Thus, the probability that we will win is \(\frac{1}{2}\)</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Square Cross</title><link href="http://localhost:4000/probability/problems/2025/03/28/Square-Cross.html" rel="alternate" type="text/html" title="Square Cross" /><published>2025-03-28T00:00:00+05:30</published><updated>2025-03-28T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/28/Square-Cross</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/28/Square-Cross.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>A square of side length \(20\) is placed in front of you. You select a point uniformly at random from its interior. Then, independently, a circle of radius \(R \sim \text{Unif}(0,10)\) is formed around the selected point. What is the probability that this circle does not intersect the square at any point?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/square-cross">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1---understanding-the-core-idea">Step 1 - Understanding the Core Idea</h3>

<p>Let’s build some intuition. Clearly, the best place to pick a point is the center of the square—a circle centered there can grow up to radius \(10\) before touching an edge. Any point away from the center? Well, that’s where things get tricky—closer points to the boundary have a higher chance of their circle spilling out.</p>

<p>Try to visualize the locus of all points that are an equal distance from the closest edge. These points form a smaller concentric square, with perpendicular distance \(x\) from the center. Our goal is now clear:</p>

<ol>
  <li>Find the probability of choosing a point at a given \(x\).</li>
  <li>Given \(x\), find the probability that a circle centered there does not intersect the square.</li>
  <li>Integrate over all possible \(x\).</li>
</ol>

<h4 id="visualizing-the-locus">Visualizing the Locus</h4>

<p>The points that are an equal distance from the nearest edge form a square frame at distance \(x\). Here’s what it looks like:</p>

<p><img src="/assets/images/squarecross.png" alt="Visualization" /></p>

<p><em>(Yeah ik the diagram kinda sucks, but I believe in MS-Paint XD. Anyhow)</em></p>

<p>Key observations:</p>

<ol>
  <li>All points on the same locus are equivalent. The probability of a circle touching the square depends only on \(x\), not on the specific point along the locus.</li>
  <li>Probability of picking a point at distance \(x\):
    <ul>
      <li>The area of the square frame at distance \(x\) is<br />
\(4 \times (2x) \times dx = 8x \, dx\)</li>
      <li>Since the total area of the square is \(400\), the probability of selecting a point from this region is<br />
\(\frac{8x \, dx}{400} = \frac{x \, dx}{50}\)</li>
    </ul>
  </li>
</ol>

<h3 id="step-2---computing-the-probability">Step 2 - Computing the Probability</h3>

<p>Now, assume a point at distance \(x\) has been chosen. What is the probability that a randomly chosen radius does not cause intersection?</p>

<ul>
  <li>The favorable radii are those that do not exceed \(x\), i.e., \(R \in [0, 10-x]\)</li>
  <li>Since \(R \sim \text{Unif}(0,10)\), the probability that \(R \leq 10 - x\) is simply \(\frac{10 - x}{10}\)</li>
</ul>

<p>Thus, our probability function is now completely defined. To compute the final probability, we integrate:</p>

\[P(\text{No intersection}) = \int_0^{10} \frac{10-x}{10} \cdot \frac{x}{50} \, dx\]

<p>Expanding:</p>

\[P(\text{No intersection}) = \frac{1}{500} \int_0^{10} x(10-x) \, dx\]

<p>Breaking it down:</p>

\[\frac{1}{500} \int_0^{10} (10x - x^2) \, dx\]

<p>Computing the integral,</p>

\[\frac{1}{500} \left[ 5x^2 - \frac{x^3}{3} \right]_0^{10}\]

\[= \frac{1}{500} \left[ 500 - \frac{1000}{3} \right]\]

\[= \frac{1}{500} \times \frac{500}{3}\]

\[= \frac{1}{3}\]

<h3 id="thus-the-probability-that-the-circle-does-not-intersect-the-square-is-frac13">Thus, the probability that the circle does not intersect the square is \(\frac{1}{3}\)</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Probability" /><category term="Integration" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Matching Die Trio</title><link href="http://localhost:4000/probability/problems/2025/03/24/Matching-Die-Trio.html" rel="alternate" type="text/html" title="Matching Die Trio" /><published>2025-03-24T00:00:00+05:30</published><updated>2025-03-24T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/24/Matching-Die-Trio</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/24/Matching-Die-Trio.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>Three fair \(6\)−sided dice are rolled and their upfaces are recorded. Find the probability that the values showing upon rolling all three dice again is the same as the original three values recorded.</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/matching-die-trio">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>We approach this problem using conditional expectation and casework probability. Since the three dice are not labeled, the probability of getting a matching set on the second roll depends on the structure of the first roll.</p>

<h3 id="step-1-classifying-cases-based-on-first-roll">Step 1: Classifying Cases Based on First Roll</h3>

<p>When rolling three fair 6-sided dice, the possible cases based on distinctness of numbers are:</p>

<ol>
  <li><strong>Case 1: All three dice show distinct numbers.</strong>
    <ul>
      <li>The probability of this occurring:
\(P(C_1) = \frac{\binom{6}{3} \cdot 3!}{6^3} = \frac{20 \cdot 6}{216} = \frac{120}{216}\)</li>
      <li>On re-rolling, all 3 numbers must appear again. The number of favorable outcomes is the <strong>number of ways to permute the same three numbers</strong>, which is \(3!\).
        <ul>
          <li>Probability of matching:
\(P(M \mid C_1) = \frac{3!}{6^3} = \frac{6}{216}\)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Case 2: Two dice show the same number, and the third is different.</strong>
    <ul>
      <li>The probability of this occurring:
\(P(C_2) = \frac{\binom{6}{1} \cdot \binom{5}{1} \cdot \frac{3!}{2!}}{6^3} = \frac{6 \cdot 5 \cdot 3}{216} = \frac{90}{216}\)</li>
      <li>On re-rolling, we must obtain the same structure (two of one number and one of another), and the arrangement of dice does not matter.
        <ul>
          <li>Probability of matching:
\(P(M \mid C_2) = \frac{\frac{3!}{2!}}{6^3} = \frac{3}{216}\)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Case 3: All three dice show the same number.</strong>
    <ul>
      <li>The probability of this occurring:
\(P(C_3) = \frac{6}{216}\)</li>
      <li>On re-rolling, the only way to match is if the same number appears on all three dice.
        <ul>
          <li>Probability of matching:
\(P(M \mid C_3) = \frac{1}{6^3} = \frac{1}{216}\)</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h3 id="step-2-computing-the-final-probability">Step 2: Computing the Final Probability</h3>

<p>Using the Law of Total Probability:</p>

\[P(M) = P(M \mid C_1) P(C_1) + P(M \mid C_2) P(C_2) + P(M \mid C_3) P(C_3)\]

<p>Substituting values:</p>

\[P(M) = \left(\frac{6}{216} \times \frac{120}{216}\right) + \left(\frac{3}{216} \times \frac{90}{216}\right) + \left(\frac{1}{216} \times \frac{6}{216}\right)\]

\[P(M) = \frac{720}{46656} + \frac{270}{46656} + \frac{6}{46656}\]

\[P(M) = \frac{996}{46656}\]

\[P(M) = \frac{83}{3888}\]

<h3 id="thus-the-probability-that-the-second-roll-matches-the-first-roll-is-frac833888">Thus, the probability that the second roll matches the first roll is \(\frac{83}{3888}\)</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Combinatorics" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Graph Search I</title><link href="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-I.html" rel="alternate" type="text/html" title="Graph Search I" /><published>2025-03-23T00:00:00+05:30</published><updated>2025-03-23T00:00:00+05:30</updated><id>http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-I</id><content type="html" xml:base="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-I.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You are given an undirected graph with \(10\) nodes. From every node, you are able to access any other node (including itself), all with an equal probability of \(\frac{1}{10}\). What is the expected number of steps to reach all nodes at least once (rounded to the nearest step)?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/graph-search">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>It is clear that we must deal with conditional expectations in the given problem. As a recap, using conditional expectations, we get</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-formulating-recursive-relation">Step 1: Formulating Recursive Relation</h3>

<p>Lets denote \(E_{i}\) as the expected number of steps required to  visit \(i\) un-visited nodes. Note that this does not count our current node.</p>

<p>Now, when the simulation starts, you will take 1 step and enter the first node. After this, 9 nodes remain to be visited. Now, when you take the next path, either you end up on the same node (with probability \(\frac{1}{10}\)) or you end up on a new node (with probability \(\frac{9}{10}\)). Note that, when you enter a new node, now the remaining expected number of steps will be \(E_{8}\), as you have already visited 2 nodes.</p>

<p>Therefore, for our first iteration, we could write
\(E_{9} = (\frac{1}{10} \times (1 + E_{9})) + (\frac{9}{10} \times (1 + E_{8}))\)</p>

<p>Note that the + 1 is added in each term as you take one step to reach there.</p>

<h3 id="step-2-generalizing-the-relation">Step 2: Generalizing the Relation</h3>

<p>After a few iterations, it will be clear that the relation can be generalized as follows -</p>
<blockquote>
  <p>“If you must visit n nodes more, then with probability \(\frac{10 - n}{10}\) you will reach an already visited node (where you will take \(E_{n}\) steps), and with probability \(\frac{n}{10}\) you will visit a new node (where you will take \(E_{n-1}\) steps).”</p>
</blockquote>

<p>Therefore,</p>

\[E_{n} = (\frac{10 - n}{10} \times (1 + E_{n})) + (\frac{n}{10} \times (1 + E_{n-1}))\]

<p>On simplification, we get</p>

\[E_{n} = \frac{10}{n} + E_{n-1}\]

<h3 id="step-3-solving-recursion">Step 3: Solving Recursion</h3>

<p>Now that we have established the recurrence relation</p>

\[E_{n} = \frac{10}{n} + E_{n-1},\]

<p>we can solve it iteratively to find a general expression for \(E_{9}\), which is the expected number of steps to visit 9 new nodes. Note that we will need to add one more step, which is to “start” the simulation, i.e. enter the graph in the first place, and visit our first node.</p>

<p>First, note that the recurrence starts with \(E_{0} = 0\) since when no nodes are unvisited, no more steps are required.</p>

<p>Now, let’s compute the values step by step:</p>

<ul>
  <li>
    <p>For \(E_1\):
\(E_1 = \frac{10}{1} + E_0 = 10 + 0 = 10.\)</p>
  </li>
  <li>
    <p>For \(E_2\):
\(E_2 = \frac{10}{2} + E_1 = 5 + 10 = 15.\)</p>
  </li>
  <li>
    <p>For \(E_3\):
\(E_3 = \frac{10}{3} + E_2 = \frac{10}{3} + 15 \approx 3.33 + 15 = 18.33.\)</p>
  </li>
  <li>
    <p>For \(E_4\):
\(E_4 = \frac{10}{4} + E_3 = 2.5 + 18.33 \approx 20.83.\)</p>
  </li>
  <li>
    <p>For \(E_5\):
\(E_5 = \frac{10}{5} + E_4 = 2 + 20.83 \approx 22.83.\)</p>
  </li>
  <li>
    <p>For \(E_6\):
\(E_6 = \frac{10}{6} + E_5 = \frac{5}{3} + 22.83 \approx 1.67 + 22.83 = 24.5.\)</p>
  </li>
  <li>
    <p>For \(E_7\):
\(E_7 = \frac{10}{7} + E_6 = \frac{10}{7} + 24.5 \approx 1.43 + 24.5 = 25.93.\)</p>
  </li>
  <li>
    <p>For \(E_8\):
\(E_8 = \frac{10}{8} + E_7 = \frac{5}{4} + 25.93 \approx 1.25 + 25.93 = 27.18.\)</p>
  </li>
  <li>
    <p>For \(E_9\):
\(E_9 = \frac{10}{9} + E_8 = \frac{10}{9} + 27.18 \approx 1.11 + 27.18 = 28.29.\)</p>
  </li>
</ul>

<p>Finally, for our final answer, as discussed above, we have:</p>

\[Ans = 1 + E_9 = 1 + 28.29 \approx 29.29\]

<h3 id="thus-the-expected-number-of-steps-to-visit-all-10-nodes-at-least-once-is-approximately-2929-which-rounds-to-29-steps">Thus, the expected number of steps to visit all 10 nodes at least once is approximately <strong>29.29</strong>, which rounds to <strong>29</strong> steps.</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Expectations" /><category term="Probability" /><category term="Problems" /><category term="Expectations" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Particle Reach</title><link href="http://localhost:4000/probability/problems/2025/03/23/Particle-Reach.html" rel="alternate" type="text/html" title="Particle Reach" /><published>2025-03-23T00:00:00+05:30</published><updated>2025-03-23T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/23/Particle-Reach</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/23/Particle-Reach.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>Consider a particle that performs a random walk on the integers starting at position \(0\). At each step, the particle moves from position \(i\) to position \(i+1\) with probability \(p\), while the probability it moves from \(i\) to \(i−1\) is \(1−p\). If \(p=\frac{1}{3}\), find the probability the particle ever reaches position \(1\)</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/particle-reach-i">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>It is obvious that counting cases is not feasible here. Clearly there are infinitely many cases, with no clear pattern leading to a solvable series summation. Instead, lets deal with conditional probabilities.</p>

<p>To recall,</p>

\[P(X) = \sum_{Y_i} P(X | Y_i) \times P(Y_i)\]

<h3 id="step-1-basic-observations">Step 1: Basic Observations</h3>

<p>There is a key observation here. I pose the following question</p>
<blockquote>
  <p>“If the particle started at position -1, what will be the probability of it ever reaching 0? How about 1?”</p>
</blockquote>

<p>Note that, the particle’s probability of reaching 0 is the same as that of a particle’s probability of reach 1 when it starts at 0. This is because this random walk does not depend on your current position, just relative distances.</p>

<p>Now, what about the second part? Say I denote the probability of particle reaching the position to its just right as \(p_1\).
Note that in this case, the</p>

<p>probability of particle reaching 2 steps to the right = P(Particle reaching 1 step right) * P(Particle reaching 1 step right)</p>

<p>How? Positional independence! As stated earlier, in this random walk, the probabilities are independent of your current position! This is essentially the product of 2 independent events, which are</p>
<ul>
  <li>Particle Reaching 1 step to the right</li>
  <li>Particle reaching another step to the right from this new position (making total distance 2)</li>
</ul>

<p>Thus, \(p_2 = p_1^{2}\)</p>

<h3 id="step-2-equation-formation-and-solution">Step 2: Equation Formation and Solution</h3>

<p>Now, lets use the law of total probability to form an equation in \(p_1\).</p>

<p>We know,</p>

\[P(X) = \sum_{Y_i} P(X | Y_i) \times P(Y_i)\]

<p>Here, from the origin, 2 events are possible</p>

<ul>
  <li>The particle moves one step right to 1, with probability \(p\)</li>
  <li>The particle moves one step left to -1, with probability \(1-p\)</li>
</ul>

<p>Lets denote our event “particle reaching position 1” as \(X\)
Also, \(Y_i\) would represent the particle moving either left or right.
Let \(Y_1\) be particle moving left. This \(P(Y_1) = 1 - p\). Similarly, let \(Y_2\) be particle moving right. This \(P(Y_2) = p\).</p>

<p>Also, from our discussion earlier, \(P(X \mid Y_1) = p_2 = p_1^{2}\), and \(P(X \mid Y_2) = 1\). Ofcourse, \(P(X) = p_1\), and \(p = \frac{1}{3}\), as given in the question.</p>

<p>Plugging the values and simplifying, we get the equation</p>

\[2p_1^{2} - 3p_1 + 1 = 0\]

<p>Solving, we get \(p_1 = 1, \frac{1}{2}\)</p>

<p>Clearly, \(p_1 != 1\).</p>

<h3 id="thus-the-required-probability-is-frac12">Thus, the required probability is \(\frac{1}{2}\)</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Random Walks" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Graph Search II</title><link href="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-II.html" rel="alternate" type="text/html" title="Graph Search II" /><published>2025-03-23T00:00:00+05:30</published><updated>2025-03-23T00:00:00+05:30</updated><id>http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-II</id><content type="html" xml:base="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-II.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You are given an undirected graph with \(11\) nodes. From every node, you are able to access any other node (not including itself), all with an equal probability of \(\frac{1}{10}\). What is the expected number of steps to reach all nodes at least once (rounded to the nearest step)?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/graph-search-ii">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>It is clear that we must deal with conditional expectations in the given problem. As a recap, using conditional expectations, we get</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-formulating-recursive-relation">Step 1: Formulating Recursive Relation</h3>

<p>Lets denote \(E_{i}\) as the expected number of steps required to  visit \(i\) un-visited nodes. Note that this does not count our current node.</p>

<p>Now, when the simulation starts, you will take 1 step and enter the first node. After this, 10 nodes remain to be visited. Now, when you take the next path, you will definitely end up on a new node (as all other nodes are unvisited). Lets say this step is done. Now, you are on your 2nd node, with 9 unvisited, and 1 visited. Now, with probability \(\frac{1}{10}\), you may end up on an already visited note, and with probability \(\frac{9}{10}\), you may end up on a new un-visited node.</p>

<p>Therefore, for our second iteration, we could write
\(E_{9} = (\frac{1}{10} \times (1 + E_{9})) + (\frac{9}{10} \times (1 + E_{8}))\)</p>

<p>Note that the + 1 is added in each term as you take one step to reach there.</p>

<h3 id="step-2-generalizing-the-relation">Step 2: Generalizing the Relation</h3>

<p>After a few iterations, it will be clear that the relation can be generalized as follows -</p>
<blockquote>
  <p>“If you must visit n nodes more, then with probability \(\frac{10 - n}{10}\) you will reach an already visited node (where you will take \(E_{n}\) steps), and with probability \(\frac{n}{10}\) you will visit a new node (where you will take \(E_{n-1}\) steps).”</p>
</blockquote>

<p>Therefore,</p>

\[E_{n} = (\frac{10 - n}{10} \times (1 + E_{n})) + (\frac{n}{10} \times (1 + E_{n-1}))\]

<p>On simplification, we get</p>

\[E_{n} = \frac{10}{n} + E_{n-1}\]

<h3 id="step-3-solving-recursion">Step 3: Solving Recursion</h3>

<p>Now that we have established the recurrence relation</p>

\[E_{n} = \frac{10}{n} + E_{n-1},\]

<p>we can solve it iteratively to find a general expression for \(E_{10}\), which is the expected number of steps to visit all 10 new nodes at least once. Note that we will also need to add 1 to this, as that will mark our “first” step into the graph (because its only on our first node we need to walk \(E_{10}\) steps more. We must include that first step to our first node as well).</p>

<p>First, note that the recurrence starts with \(E_{0} = 0\) since when no nodes are unvisited, no more steps are required.</p>

<p>Now, let’s compute the values step by step:</p>

<ul>
  <li>
    <p>For \(E_1\):
\(E_1 = \frac{10}{1} + E_0 = 10 + 0 = 10.\)</p>
  </li>
  <li>
    <p>For \(E_2\):
\(E_2 = \frac{10}{2} + E_1 = 5 + 10 = 15.\)</p>
  </li>
  <li>
    <p>For \(E_3\):
\(E_3 = \frac{10}{3} + E_2 = \frac{10}{3} + 15 \approx 3.33 + 15 = 18.33.\)</p>
  </li>
  <li>
    <p>For \(E_4\):
\(E_4 = \frac{10}{4} + E_3 = 2.5 + 18.33 \approx 20.83.\)</p>
  </li>
  <li>
    <p>For \(E_5\):
\(E_5 = \frac{10}{5} + E_4 = 2 + 20.83 \approx 22.83.\)</p>
  </li>
  <li>
    <p>For \(E_6\):
\(E_6 = \frac{10}{6} + E_5 = \frac{5}{3} + 22.83 \approx 1.67 + 22.83 = 24.5.\)</p>
  </li>
  <li>
    <p>For \(E_7\):
\(E_7 = \frac{10}{7} + E_6 = \frac{10}{7} + 24.5 \approx 1.43 + 24.5 = 25.93.\)</p>
  </li>
  <li>
    <p>For \(E_8\):
\(E_8 = \frac{10}{8} + E_7 = \frac{5}{4} + 25.93 \approx 1.25 + 25.93 = 27.18.\)</p>
  </li>
  <li>
    <p>For \(E_9\):
\(E_9 = \frac{10}{9} + E_8 = \frac{10}{9} + 27.18 \approx 1.11 + 27.18 = 28.29.\)</p>
  </li>
  <li>
    <p>Finally, for \(E_{10}\):
\(E_{10} = \frac{10}{10} + E_9 = 1 + 28.29 \approx 29.29.\)</p>
  </li>
</ul>

<p>As discussed earlier, we must add 1 to account for our first step on the 11th node (from where we start exploring the remaining 10 nodes). Therefore,</p>

\[Ans = 1 + E_10 = 1 + 29.29 \approx 30.29.\]

<h3 id="thus-the-expected-number-of-steps-to-visit-all-11-nodes-at-least-once-is-approximately-3029-which-rounds-to-30-steps">Thus, the expected number of steps to visit all 11 nodes at least once is approximately <strong>30.29</strong>, which rounds to <strong>30</strong> steps.</h3>

<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Expectations" /><category term="Probability" /><category term="Problems" /><category term="Expectations" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Mean babysitter</title><link href="http://localhost:4000/combinatorics/statistics/problems/2025/03/21/Mean-babysitter.html" rel="alternate" type="text/html" title="Mean babysitter" /><published>2025-03-21T00:00:00+05:30</published><updated>2025-03-21T00:00:00+05:30</updated><id>http://localhost:4000/combinatorics/statistics/problems/2025/03/21/Mean-babysitter</id><content type="html" xml:base="http://localhost:4000/combinatorics/statistics/problems/2025/03/21/Mean-babysitter.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>10 kids are really hungry! Their babysitter has 12 units of food to give. However, she decides she only wants to give 4 of the children food. How many ways can she distribute the food units such that 6 of the children are hungry (receive no food), and the other 4 children receive at least 1 unit of food each?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/mean-babysitter">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1-understanding-the-required-tasks">Step 1: Understanding the Required Tasks</h3>

<p>To distribute the food, we need to:</p>

<ol>
  <li>Choose 4 children who will receive food (equivalently, choose 6 children who won’t).</li>
  <li>Distribute 12 units of food among these 4 children, ensuring that each child gets at least 1 unit.</li>
</ol>

<h3 id="step-2-calculating-the-number-of-ways">Step 2: Calculating the Number of Ways</h3>

<h4 id="step-1-choosing-4-children"><strong>Step 1: Choosing 4 Children</strong></h4>
<p>Since we need to select 4 children out of 10, the number of ways to do this is:</p>

\[\binom{10}{4} = \binom{10}{6} = 210\]

<p>(since choosing 4 to receive food is the same as choosing 6 to not receive food).</p>

<h4 id="step-2-distributing-the-food"><strong>Step 2: Distributing the Food</strong></h4>
<p>Let the food received by the four chosen children be represented as:</p>

\[f_{a} + f_{b} + f_{c} + f_{d} = 12\]

<p>where \(f_{a}, f_{b}, f_{c}, f_{d}\) represent the food units received by each of the 4 children.</p>

<p>Since each child must get at least 1 unit, we make the substitution:</p>

\[f_{a} = 1 + x_{a}, \quad f_{b} = 1 + x_{b}, \quad f_{c} = 1 + x_{c}, \quad f_{d} = 1 + x_{d}\]

<p>Rewriting the equation:</p>

\[(1 + x_{a}) + (1 + x_{b}) + (1 + x_{c}) + (1 + x_{d}) = 12\]

<p>which simplifies to:</p>

\[x_{a} + x_{b} + x_{c} + x_{d} = 8\]

<p>This is now a classic “stars and bars” problem, where we distribute 8 extra food units among 4 children. The number of ways to do this is:</p>

\[\binom{8 + 4 - 1}{4 - 1} = \binom{11}{3} = 165\]

<h3 id="step-3-computing-the-final-answer">Step 3: Computing the Final Answer</h3>

<p>The total number of valid distributions is:</p>

\[\binom{10}{4} \times \binom{11}{3} = 210 \times 165 = 34,650\]

<h3 id="therefore-the-total-number-of-ways-is-mathbf34650">Therefore, the total number of ways is \(\mathbf{34650}\)</h3>
<hr />

<p>💡 Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Combinatorics" /><category term="Statistics" /><category term="Problems" /><category term="Combinatorics" /><category term="Counting" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Differ by 2</title><link href="http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2.html" rel="alternate" type="text/html" title="Differ by 2" /><published>2025-03-18T00:00:00+05:30</published><updated>2025-03-18T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>How many times do we have to roll a fair 6-sided die till we roll two numbers in a row that differ by 2?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/differ-by-2">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>Here, starting from the first roll, ofcourse each number is equally likely to show, with a probability of \(1/6\). Hypothetically, we could compute each possible suitable combination (1-3, 3-1, 2-4, 4-2 …) and compute its probability. Summing this in the standard method of computing Expectation, we could get the answer, but clearly this method is very tedious, time-consuming and computationally heavy.</p>

<p>A better alternative is to use the concept of Conditional Expectations.
It essentially states that</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-identifying-states">Step 1: Identifying States</h3>

<p>In the described problem, the dice can show 6 possible faces. This means, we can identify 6 different unique states \(S_{1}\), \(S_{2}\), \(S_{3}\), \(S_{4}\), \(S_{5}\), \(S_{6}\).</p>

<p>This reduces our problem to a Markov Chain analysis, with transition probablities from each state to each other state as \(1/6\).</p>

<p>How? Essentially, each State \(S_{i}\) represents that the die showed i in the first roll. If I roll it again, then either the number will differ by 2 (leading to the simulation being stopped there), or it will show another number, and our analysis essentially “resets” with a new number as our first number. (Ofcourse we will account for the fact that we did take 1 roll to each this new State).</p>

<p>We also note another interesting observation here.</p>

<p>I propose this - “The expected no. of rolls for our problem, given that the first roll returned 1, is the same as the expected no. of rolls given that the first roll returned 6”</p>

<p>How? Simply because 1 and 6 are essentially symmetric. If I get 1 as my first roll, only 3 in the next roll would stop my simulation (Thus only 1 possible value will stop). Same goes for 6 (only 4 can fulfill the condition). Infact, same goes for 2 and 5!. If I get 2, only 4 can stop, and if I get 5, only 3 can stop my simulation.</p>

<p>Thus, \(E[X \mid 1] = E[X \mid 2] = E[X \mid 5] = E[X \mid 6]\), where \(E[X \mid i]\) represents the expected number of turns, given that the die started from face i.</p>

<p>As you may have guessed, we can do a similar analysis for \(E[X \mid 3]\) and \(E[X \mid 4]\). If my first roll gives 3, I have 2 possible cases (1 and 5) where my simulation ends in the next step. Same for if my first roll gives 4, because then either 2 or 6 will stop the simulation. Thus, by symmetry, 
\(E[X \mid 3] = E[X \mid 4]\).</p>

<p>Now, yet another fact!</p>

<p>Clearly, \(E[X] = 1/6 (1 + E[X \mid 1]) + 1/6 (1 + E[X \mid 2]) + 1/6 (1 + E[X \mid 3]) + 1/6 (1 + E[X \mid 4]) + 1/6 (1 + E[X \mid 5]) + 1/6 (1 + E[X \mid 5])\)</p>

<p>How? - Exercise to reader!</p>

<p>Thus, we can reduce the problem to</p>

<blockquote>
  <p>“Given the state transition probability 1/6 and the dependence between the states, find \(E[X \mid 1]... E[X \mid 6]\), where \(X\) is the event of getting 2 rolls differing by 2, and \(E[X \mid i]\) represents starting the experiment with face i”</p>
</blockquote>

<h3 id="step-2-forming-the-set-of-expectation-equations">Step 2: Forming the set of Expectation equations</h3>

<p>For each state \(i\), we compute \(E[X\mid i]\). But as discussed, since there is symmetry, it is sufficient to just compute \(E[X \mid 1]\) and \(E[X \mid 3]\).</p>

<p>Now,</p>

\[E[X \mid 1] = \frac{1}{6} (E[X \mid 1,1]) + \frac{1}{6} (E[X \mid 1,2]) + \frac{1}{6} (E[X \mid 1,3]) + \frac{1}{6} (E[X \mid 1,4]) + \frac{1}{6} (E[X \mid 1,5]) + \frac{1}{6} (E[X \mid 1,6])\]

<p>Substituting:</p>

<ul>
  <li>\(E[X \mid 1,3] = 1\) since rolling a 3 stops the process. (Thus only 1 step required till 3 from 1)</li>
  <li>\(E[X \mid 1,j] = 1 + E[X \mid j]\) for all other \(j\), since the process resets but after one step.</li>
</ul>

<p>Thus,</p>

\[E[X \mid 1] = \frac{1}{6} (1 + E[X \mid 1]) + \frac{1}{6} (1 + E[X \mid 2]) + \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 4]) + \frac{1}{6} (1 + E[X \mid 5]) + \frac{1}{6} (1 + E[X \mid 6])\]

<p>Similarly, for \(E[X \mid 3]\):</p>

\[E[X \mid 3] = \frac{1}{6} (E[X \mid 3,1]) + \frac{1}{6} (E[X \mid 3,2]) + \frac{1}{6} (E[X \mid 3,3]) + \frac{1}{6} (E[X \mid 3,4]) + \frac{1}{6} (E[X \mid 3,5]) + \frac{1}{6} (E[X \mid 3,6])\]

<p>Substituting:</p>

<ul>
  <li>\(E[X \mid 3,1] = 1\), since rolling a 1 stops the process.</li>
  <li>\(E[X \mid 3,5] = 1\), since rolling a 5 stops the process.</li>
  <li>\(E[X \mid 3,j] = 1 + E[X \mid j]\) for all other \(j\).</li>
</ul>

<p>Thus,</p>

\[E[X \mid 3] = \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 2]) + \frac{1}{6} (1 + E[X \mid 3]) + \frac{1}{6} (1 + E[X \mid 4]) + \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 6])\]

<h3 id="step-3-solving-the-equations">Step 3: Solving the equations</h3>

<p>Now, using:</p>

\[a = E[X \mid 1] = E[X \mid 2] = E[X \mid 5] = E[X \mid 6]\]

\[b = E[X \mid 3] = E[X \mid 4]\]

<p>Substitute these into the equations made above, and simplify, to get:</p>

\[a = 1 + \frac{1}{6} (a + a + b + a + a)\]

\[b = 1 + \frac{1}{6} (a + a + b + b)\]

<p>Solving these, we get:</p>

\[a = 5, \quad b = 4\]

<p>Finally, computing \(E[X]\):</p>

\[E[X] = 1 + \frac{1}{6} (a + a + b + b + a + a) = 1 + \frac{4a + 2b}{6}\]

\[E[X] = 1 + \frac{4 \times 5 + 2 \times 4}{6} = 1 + \frac{14}{3}\]

\[E[X] = \frac{17}{3}\]

<h3 id="therefore-the-expected-number-of-moves-required-for-the-ant-to-reach-back-to-its-starting-point-is-frac173">Therefore, the expected number of moves required for the ant to reach back to its starting point is \(\frac{17}{3}\)</h3>

<hr />

<p>💡  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry></feed>