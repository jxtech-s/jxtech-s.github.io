<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-29T02:44:24+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">JXTech</title><subtitle>Advanced probability problems and detailed solutions</subtitle><author><name>JXTech</name></author><entry><title type="html">Square Cross</title><link href="http://localhost:4000/probability/problems/2025/03/28/Square-Cross.html" rel="alternate" type="text/html" title="Square Cross" /><published>2025-03-28T00:00:00+05:30</published><updated>2025-03-28T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/28/Square-Cross</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/28/Square-Cross.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>A square of side length \(20\) is placed in front of you. You select a point uniformly at random from its interior. Then, independently, a circle of radius \(R \sim \text{Unif}(0,10)\) is formed around the selected point. What is the probability that this circle does not intersect the square at any point?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/square-cross">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1---understanding-the-core-idea">Step 1 - Understanding the Core Idea</h3>

<p>Let‚Äôs build some intuition. Clearly, the best place to pick a point is the center of the square‚Äîa circle centered there can grow up to radius \(10\) before touching an edge. Any point away from the center? Well, that‚Äôs where things get tricky‚Äîcloser points to the boundary have a higher chance of their circle spilling out.</p>

<p>Try to visualize the locus of all points that are an equal distance from the closest edge. These points form a smaller concentric square, with perpendicular distance \(x\) from the center. Our goal is now clear:</p>

<ol>
  <li>Find the probability of choosing a point at a given \(x\).</li>
  <li>Given \(x\), find the probability that a circle centered there does not intersect the square.</li>
  <li>Integrate over all possible \(x\).</li>
</ol>

<h4 id="visualizing-the-locus">Visualizing the Locus</h4>

<p>The points that are an equal distance from the nearest edge form a square frame at distance \(x\). Here‚Äôs what it looks like:</p>

<p><img src="/assets/images/squarecross.png" alt="Visualization" /></p>

<p><em>(Yeah ik the diagram kinda sucks, but I believe in MS-Paint XD. Anyhow)</em></p>

<p>Key observations:</p>

<ol>
  <li>All points on the same locus are equivalent. The probability of a circle touching the square depends only on \(x\), not on the specific point along the locus.</li>
  <li>Probability of picking a point at distance \(x\):
    <ul>
      <li>The area of the square frame at distance \(x\) is<br />
\(4 \times (2x) \times dx = 8x \, dx\)</li>
      <li>Since the total area of the square is \(400\), the probability of selecting a point from this region is<br />
\(\frac{8x \, dx}{400} = \frac{x \, dx}{50}\)</li>
    </ul>
  </li>
</ol>

<h3 id="step-2---computing-the-probability">Step 2 - Computing the Probability</h3>

<p>Now, assume a point at distance \(x\) has been chosen. What is the probability that a randomly chosen radius does not cause intersection?</p>

<ul>
  <li>The favorable radii are those that do not exceed \(x\), i.e., \(R \in [0, 10-x]\)</li>
  <li>Since \(R \sim \text{Unif}(0,10)\), the probability that \(R \leq 10 - x\) is simply \(\frac{10 - x}{10}\)</li>
</ul>

<p>Thus, our probability function is now completely defined. To compute the final probability, we integrate:</p>

\[P(\text{No intersection}) = \int_0^{10} \frac{10-x}{10} \cdot \frac{x}{50} \, dx\]

<p>Expanding:</p>

\[P(\text{No intersection}) = \frac{1}{500} \int_0^{10} x(10-x) \, dx\]

<p>Breaking it down:</p>

\[\frac{1}{500} \int_0^{10} (10x - x^2) \, dx\]

<p>Computing the integral,</p>

\[\frac{1}{500} \left[ 5x^2 - \frac{x^3}{3} \right]_0^{10}\]

\[= \frac{1}{500} \left[ 500 - \frac{1000}{3} \right]\]

\[= \frac{1}{500} \times \frac{500}{3}\]

\[= \frac{1}{3}\]

<h3 id="thus-the-probability-that-the-circle-does-not-intersect-the-square-is-frac13">Thus, the probability that the circle does not intersect the square is \(\frac{1}{3}\)</h3>

<hr />

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Probability" /><category term="Integration" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Modified RNG</title><link href="http://localhost:4000/probability/problems/2025/03/28/Modified-RNG.html" rel="alternate" type="text/html" title="Modified RNG" /><published>2025-03-28T00:00:00+05:30</published><updated>2025-03-28T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/28/Modified-RNG</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/28/Modified-RNG.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>Jimmy picks a number uniformly at random from (0,1). If Jimmy chooses x, then Jon picks a number from (x,1) uniformly at random. If Y represents the number Jon selects, in simplest form, find \(\frac{\mathbb{E}[Y]}{Var(Y)}\)</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/modified-rng">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1---compute-conditional-expectation-mathbbey-mid-x-and-conditional-variance-vary-mid-x">Step 1 - Compute Conditional Expectation \(\mathbb{E}[Y \mid X]\) and Conditional Variance \(Var(Y \mid X)\)</h3>

<p>For \(Y\) uniform on \((X,1)\), the conditional expectation is:</p>

\[\mathbb{E}[Y \mid X] = \frac{X+1}{2}\]

<p>How? Its obvious that its gonna be the middle point! Alternatively, you can integrate and compute using the standard method.</p>

<p>Similarly, for Conditional Variance \(Var[Y \mid X]\), we have</p>

\[Var[Y \mid X] = \frac{(1-X)^2}{12}\]

<h3 id="step-2---total-expectation">Step 2 - Total Expectation</h3>

<p>Using the law of total expectation:</p>

\[\mathbb{E}[Y] = \mathbb{E}[\mathbb{E}[Y \mid X]] = \mathbb{E}\left[\frac{X+1}{2}\right] = \int_0^1 \frac{x+1}{2} dx = \left[\frac{x^2}{4} + \frac{x}{2}\right]_0^1 = \frac{1}{4} + \frac{1}{2} = \frac{3}{4}\]

<h3 id="step-3---computing-total-variance">Step 3 - Computing Total Variance</h3>

<p>Using the law of total variance:</p>

\[Var(Y) = \mathbb{E}[Var(Y \mid X)] + Var(\mathbb{E}[Y \mid X])\]

<p>First, compute \(\mathbb{E}[Var(Y \mid X)]\):</p>

\[\mathbb{E}[Var(Y \mid X)] = \int_0^1 \frac{(1-x)^2}{12} dx\]

\[= \frac{1}{12} \int_0^1 (1-x)^2 dx = \frac{1}{12} \left[\frac{-1}{3}(1-x)^3\right]_0^1 = \frac{1}{12} \cdot \frac{1}{3} = \frac{1}{36}\]

<p>Next, compute \(Var(\mathbb{E}[Y \mid X])\):</p>

\[Var(\mathbb{E}[Y \mid X]) = \mathbb{E}\left[\left(\frac{X+1}{2}\right)^2\right] - \left(\mathbb{E}\left[\frac{X+1}{2}\right]\right)^2\]

\[= \int_0^1 \frac{(x+1)^2}{4} dx - \left(\frac{3}{4}\right)^2 = \frac{1}{4} \int_0^1 (x^2 + 2x + 1) dx - \frac{9}{16}\]

\[= \frac{1}{4} \left[\frac{x^3}{3} + x^2 + x\right]_0^1 - \frac{9}{16} = \frac{1}{4} \left(\frac{1}{3} + 1 + 1\right) - \frac{9}{16} = \frac{1}{4} \cdot \frac{7}{3} - \frac{9}{16} = \frac{7}{12} - \frac{9}{16} = \frac{1}{48}\]

<p>Therefore:</p>

\[Var(Y) = \frac{1}{36} + \frac{1}{48} = \frac{7}{144}\]

<h3 id="final-answer">Final Answer</h3>

\[\frac{\mathbb{E}[Y]}{Var(Y)} = \frac{3/4}{7/144} = \frac{108}{7}\]

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><category term="Conditional Expectation" /><category term="Conditional Variance" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Matching Die Trio</title><link href="http://localhost:4000/probability/problems/2025/03/24/Matching-Die-Trio.html" rel="alternate" type="text/html" title="Matching Die Trio" /><published>2025-03-24T00:00:00+05:30</published><updated>2025-03-24T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/24/Matching-Die-Trio</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/24/Matching-Die-Trio.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>Three fair \(6\)‚àísided dice are rolled and their upfaces are recorded. Find the probability that the values showing upon rolling all three dice again is the same as the original three values recorded.</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/matching-die-trio">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>We approach this problem using conditional expectation and casework probability. Since the three dice are not labeled, the probability of getting a matching set on the second roll depends on the structure of the first roll.</p>

<h3 id="step-1-classifying-cases-based-on-first-roll">Step 1: Classifying Cases Based on First Roll</h3>

<p>When rolling three fair 6-sided dice, the possible cases based on distinctness of numbers are:</p>

<ol>
  <li><strong>Case 1: All three dice show distinct numbers.</strong>
    <ul>
      <li>The probability of this occurring:
\(P(C_1) = \frac{\binom{6}{3} \cdot 3!}{6^3} = \frac{20 \cdot 6}{216} = \frac{120}{216}\)</li>
      <li>On re-rolling, all 3 numbers must appear again. The number of favorable outcomes is the <strong>number of ways to permute the same three numbers</strong>, which is \(3!\).
        <ul>
          <li>Probability of matching:
\(P(M \mid C_1) = \frac{3!}{6^3} = \frac{6}{216}\)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Case 2: Two dice show the same number, and the third is different.</strong>
    <ul>
      <li>The probability of this occurring:
\(P(C_2) = \frac{\binom{6}{1} \cdot \binom{5}{1} \cdot \frac{3!}{2!}}{6^3} = \frac{6 \cdot 5 \cdot 3}{216} = \frac{90}{216}\)</li>
      <li>On re-rolling, we must obtain the same structure (two of one number and one of another), and the arrangement of dice does not matter.
        <ul>
          <li>Probability of matching:
\(P(M \mid C_2) = \frac{\frac{3!}{2!}}{6^3} = \frac{3}{216}\)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Case 3: All three dice show the same number.</strong>
    <ul>
      <li>The probability of this occurring:
\(P(C_3) = \frac{6}{216}\)</li>
      <li>On re-rolling, the only way to match is if the same number appears on all three dice.
        <ul>
          <li>Probability of matching:
\(P(M \mid C_3) = \frac{1}{6^3} = \frac{1}{216}\)</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h3 id="step-2-computing-the-final-probability">Step 2: Computing the Final Probability</h3>

<p>Using the Law of Total Probability:</p>

\[P(M) = P(M \mid C_1) P(C_1) + P(M \mid C_2) P(C_2) + P(M \mid C_3) P(C_3)\]

<p>Substituting values:</p>

\[P(M) = \left(\frac{6}{216} \times \frac{120}{216}\right) + \left(\frac{3}{216} \times \frac{90}{216}\right) + \left(\frac{1}{216} \times \frac{6}{216}\right)\]

\[P(M) = \frac{720}{46656} + \frac{270}{46656} + \frac{6}{46656}\]

\[P(M) = \frac{996}{46656}\]

\[P(M) = \frac{83}{3888}\]

<h3 id="thus-the-probability-that-the-second-roll-matches-the-first-roll-is-frac833888">Thus, the probability that the second roll matches the first roll is \(\frac{83}{3888}\)</h3>

<hr />

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Combinatorics" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Graph Search I</title><link href="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-I.html" rel="alternate" type="text/html" title="Graph Search I" /><published>2025-03-23T00:00:00+05:30</published><updated>2025-03-23T00:00:00+05:30</updated><id>http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-I</id><content type="html" xml:base="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-I.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You are given an undirected graph with \(10\) nodes. From every node, you are able to access any other node (including itself), all with an equal probability of \(\frac{1}{10}\). What is the expected number of steps to reach all nodes at least once (rounded to the nearest step)?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/graph-search">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>It is clear that we must deal with conditional expectations in the given problem. As a recap, using conditional expectations, we get</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-formulating-recursive-relation">Step 1: Formulating Recursive Relation</h3>

<p>Lets denote \(E_{i}\) as the expected number of steps required to  visit \(i\) un-visited nodes. Note that this does not count our current node.</p>

<p>Now, when the simulation starts, you will take 1 step and enter the first node. After this, 9 nodes remain to be visited. Now, when you take the next path, either you end up on the same node (with probability \(\frac{1}{10}\)) or you end up on a new node (with probability \(\frac{9}{10}\)). Note that, when you enter a new node, now the remaining expected number of steps will be \(E_{8}\), as you have already visited 2 nodes.</p>

<p>Therefore, for our first iteration, we could write
\(E_{9} = (\frac{1}{10} \times (1 + E_{9})) + (\frac{9}{10} \times (1 + E_{8}))\)</p>

<p>Note that the + 1 is added in each term as you take one step to reach there.</p>

<h3 id="step-2-generalizing-the-relation">Step 2: Generalizing the Relation</h3>

<p>After a few iterations, it will be clear that the relation can be generalized as follows -</p>
<blockquote>
  <p>‚ÄúIf you must visit n nodes more, then with probability \(\frac{10 - n}{10}\) you will reach an already visited node (where you will take \(E_{n}\) steps), and with probability \(\frac{n}{10}\) you will visit a new node (where you will take \(E_{n-1}\) steps).‚Äù</p>
</blockquote>

<p>Therefore,</p>

\[E_{n} = (\frac{10 - n}{10} \times (1 + E_{n})) + (\frac{n}{10} \times (1 + E_{n-1}))\]

<p>On simplification, we get</p>

\[E_{n} = \frac{10}{n} + E_{n-1}\]

<h3 id="step-3-solving-recursion">Step 3: Solving Recursion</h3>

<p>Now that we have established the recurrence relation</p>

\[E_{n} = \frac{10}{n} + E_{n-1},\]

<p>we can solve it iteratively to find a general expression for \(E_{9}\), which is the expected number of steps to visit 9 new nodes. Note that we will need to add one more step, which is to ‚Äústart‚Äù the simulation, i.e. enter the graph in the first place, and visit our first node.</p>

<p>First, note that the recurrence starts with \(E_{0} = 0\) since when no nodes are unvisited, no more steps are required.</p>

<p>Now, let‚Äôs compute the values step by step:</p>

<ul>
  <li>
    <p>For \(E_1\):
\(E_1 = \frac{10}{1} + E_0 = 10 + 0 = 10.\)</p>
  </li>
  <li>
    <p>For \(E_2\):
\(E_2 = \frac{10}{2} + E_1 = 5 + 10 = 15.\)</p>
  </li>
  <li>
    <p>For \(E_3\):
\(E_3 = \frac{10}{3} + E_2 = \frac{10}{3} + 15 \approx 3.33 + 15 = 18.33.\)</p>
  </li>
  <li>
    <p>For \(E_4\):
\(E_4 = \frac{10}{4} + E_3 = 2.5 + 18.33 \approx 20.83.\)</p>
  </li>
  <li>
    <p>For \(E_5\):
\(E_5 = \frac{10}{5} + E_4 = 2 + 20.83 \approx 22.83.\)</p>
  </li>
  <li>
    <p>For \(E_6\):
\(E_6 = \frac{10}{6} + E_5 = \frac{5}{3} + 22.83 \approx 1.67 + 22.83 = 24.5.\)</p>
  </li>
  <li>
    <p>For \(E_7\):
\(E_7 = \frac{10}{7} + E_6 = \frac{10}{7} + 24.5 \approx 1.43 + 24.5 = 25.93.\)</p>
  </li>
  <li>
    <p>For \(E_8\):
\(E_8 = \frac{10}{8} + E_7 = \frac{5}{4} + 25.93 \approx 1.25 + 25.93 = 27.18.\)</p>
  </li>
  <li>
    <p>For \(E_9\):
\(E_9 = \frac{10}{9} + E_8 = \frac{10}{9} + 27.18 \approx 1.11 + 27.18 = 28.29.\)</p>
  </li>
</ul>

<p>Finally, for our final answer, as discussed above, we have:</p>

\[Ans = 1 + E_9 = 1 + 28.29 \approx 29.29\]

<h3 id="thus-the-expected-number-of-steps-to-visit-all-10-nodes-at-least-once-is-approximately-2929-which-rounds-to-29-steps">Thus, the expected number of steps to visit all 10 nodes at least once is approximately <strong>29.29</strong>, which rounds to <strong>29</strong> steps.</h3>

<hr />

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Expectations" /><category term="Probability" /><category term="Problems" /><category term="Expectations" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Particle Reach</title><link href="http://localhost:4000/probability/problems/2025/03/23/Particle-Reach.html" rel="alternate" type="text/html" title="Particle Reach" /><published>2025-03-23T00:00:00+05:30</published><updated>2025-03-23T00:00:00+05:30</updated><id>http://localhost:4000/probability/problems/2025/03/23/Particle-Reach</id><content type="html" xml:base="http://localhost:4000/probability/problems/2025/03/23/Particle-Reach.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>Consider a particle that performs a random walk on the integers starting at position \(0\). At each step, the particle moves from position \(i\) to position \(i+1\) with probability \(p\), while the probability it moves from \(i\) to \(i‚àí1\) is \(1‚àíp\). If \(p=\frac{1}{3}\), find the probability the particle ever reaches position \(1\)</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/particle-reach-i">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>It is obvious that counting cases is not feasible here. Clearly there are infinitely many cases, with no clear pattern leading to a solvable series summation. Instead, lets deal with conditional probabilities.</p>

<p>To recall,</p>

\[P(X) = \sum_{Y_i} P(X | Y_i) \times P(Y_i)\]

<h3 id="step-1-basic-observations">Step 1: Basic Observations</h3>

<p>There is a key observation here. I pose the following question</p>
<blockquote>
  <p>‚ÄúIf the particle started at position -1, what will be the probability of it ever reaching 0? How about 1?‚Äù</p>
</blockquote>

<p>Note that, the particle‚Äôs probability of reaching 0 is the same as that of a particle‚Äôs probability of reach 1 when it starts at 0. This is because this random walk does not depend on your current position, just relative distances.</p>

<p>Now, what about the second part? Say I denote the probability of particle reaching the position to its just right as \(p_1\).
Note that in this case, the</p>

<p>probability of particle reaching 2 steps to the right = P(Particle reaching 1 step right) * P(Particle reaching 1 step right)</p>

<p>How? Positional independence! As stated earlier, in this random walk, the probabilities are independent of your current position! This is essentially the product of 2 independent events, which are</p>
<ul>
  <li>Particle Reaching 1 step to the right</li>
  <li>Particle reaching another step to the right from this new position (making total distance 2)</li>
</ul>

<p>Thus, \(p_2 = p_1^{2}\)</p>

<h3 id="step-2-equation-formation-and-solution">Step 2: Equation Formation and Solution</h3>

<p>Now, lets use the law of total probability to form an equation in \(p_1\).</p>

<p>We know,</p>

\[P(X) = \sum_{Y_i} P(X | Y_i) \times P(Y_i)\]

<p>Here, from the origin, 2 events are possible</p>

<ul>
  <li>The particle moves one step right to 1, with probability \(p\)</li>
  <li>The particle moves one step left to -1, with probability \(1-p\)</li>
</ul>

<p>Lets denote our event ‚Äúparticle reaching position 1‚Äù as \(X\)
Also, \(Y_i\) would represent the particle moving either left or right.
Let \(Y_1\) be particle moving left. This \(P(Y_1) = 1 - p\). Similarly, let \(Y_2\) be particle moving right. This \(P(Y_2) = p\).</p>

<p>Also, from our discussion earlier, \(P(X \mid Y_1) = p_2 = p_1^{2}\), and \(P(X \mid Y_2) = 1\). Ofcourse, \(P(X) = p_1\), and \(p = \frac{1}{3}\), as given in the question.</p>

<p>Plugging the values and simplifying, we get the equation</p>

\[2p_1^{2} - 3p_1 + 1 = 0\]

<p>Solving, we get \(p_1 = 1, \frac{1}{2}\)</p>

<p>Clearly, \(p_1 != 1\).</p>

<h3 id="thus-the-required-probability-is-frac12">Thus, the required probability is \(\frac{1}{2}\)</h3>

<hr />

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Problems" /><category term="Random Walks" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Graph Search II</title><link href="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-II.html" rel="alternate" type="text/html" title="Graph Search II" /><published>2025-03-23T00:00:00+05:30</published><updated>2025-03-23T00:00:00+05:30</updated><id>http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-II</id><content type="html" xml:base="http://localhost:4000/expectations/probability/problems/2025/03/23/Graph-Search-II.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You are given an undirected graph with \(11\) nodes. From every node, you are able to access any other node (not including itself), all with an equal probability of \(\frac{1}{10}\). What is the expected number of steps to reach all nodes at least once (rounded to the nearest step)?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/graph-search-ii">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>It is clear that we must deal with conditional expectations in the given problem. As a recap, using conditional expectations, we get</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-formulating-recursive-relation">Step 1: Formulating Recursive Relation</h3>

<p>Lets denote \(E_{i}\) as the expected number of steps required to  visit \(i\) un-visited nodes. Note that this does not count our current node.</p>

<p>Now, when the simulation starts, you will take 1 step and enter the first node. After this, 10 nodes remain to be visited. Now, when you take the next path, you will definitely end up on a new node (as all other nodes are unvisited). Lets say this step is done. Now, you are on your 2nd node, with 9 unvisited, and 1 visited. Now, with probability \(\frac{1}{10}\), you may end up on an already visited note, and with probability \(\frac{9}{10}\), you may end up on a new un-visited node.</p>

<p>Therefore, for our second iteration, we could write
\(E_{9} = (\frac{1}{10} \times (1 + E_{9})) + (\frac{9}{10} \times (1 + E_{8}))\)</p>

<p>Note that the + 1 is added in each term as you take one step to reach there.</p>

<h3 id="step-2-generalizing-the-relation">Step 2: Generalizing the Relation</h3>

<p>After a few iterations, it will be clear that the relation can be generalized as follows -</p>
<blockquote>
  <p>‚ÄúIf you must visit n nodes more, then with probability \(\frac{10 - n}{10}\) you will reach an already visited node (where you will take \(E_{n}\) steps), and with probability \(\frac{n}{10}\) you will visit a new node (where you will take \(E_{n-1}\) steps).‚Äù</p>
</blockquote>

<p>Therefore,</p>

\[E_{n} = (\frac{10 - n}{10} \times (1 + E_{n})) + (\frac{n}{10} \times (1 + E_{n-1}))\]

<p>On simplification, we get</p>

\[E_{n} = \frac{10}{n} + E_{n-1}\]

<h3 id="step-3-solving-recursion">Step 3: Solving Recursion</h3>

<p>Now that we have established the recurrence relation</p>

\[E_{n} = \frac{10}{n} + E_{n-1},\]

<p>we can solve it iteratively to find a general expression for \(E_{10}\), which is the expected number of steps to visit all 10 new nodes at least once. Note that we will also need to add 1 to this, as that will mark our ‚Äúfirst‚Äù step into the graph (because its only on our first node we need to walk \(E_{10}\) steps more. We must include that first step to our first node as well).</p>

<p>First, note that the recurrence starts with \(E_{0} = 0\) since when no nodes are unvisited, no more steps are required.</p>

<p>Now, let‚Äôs compute the values step by step:</p>

<ul>
  <li>
    <p>For \(E_1\):
\(E_1 = \frac{10}{1} + E_0 = 10 + 0 = 10.\)</p>
  </li>
  <li>
    <p>For \(E_2\):
\(E_2 = \frac{10}{2} + E_1 = 5 + 10 = 15.\)</p>
  </li>
  <li>
    <p>For \(E_3\):
\(E_3 = \frac{10}{3} + E_2 = \frac{10}{3} + 15 \approx 3.33 + 15 = 18.33.\)</p>
  </li>
  <li>
    <p>For \(E_4\):
\(E_4 = \frac{10}{4} + E_3 = 2.5 + 18.33 \approx 20.83.\)</p>
  </li>
  <li>
    <p>For \(E_5\):
\(E_5 = \frac{10}{5} + E_4 = 2 + 20.83 \approx 22.83.\)</p>
  </li>
  <li>
    <p>For \(E_6\):
\(E_6 = \frac{10}{6} + E_5 = \frac{5}{3} + 22.83 \approx 1.67 + 22.83 = 24.5.\)</p>
  </li>
  <li>
    <p>For \(E_7\):
\(E_7 = \frac{10}{7} + E_6 = \frac{10}{7} + 24.5 \approx 1.43 + 24.5 = 25.93.\)</p>
  </li>
  <li>
    <p>For \(E_8\):
\(E_8 = \frac{10}{8} + E_7 = \frac{5}{4} + 25.93 \approx 1.25 + 25.93 = 27.18.\)</p>
  </li>
  <li>
    <p>For \(E_9\):
\(E_9 = \frac{10}{9} + E_8 = \frac{10}{9} + 27.18 \approx 1.11 + 27.18 = 28.29.\)</p>
  </li>
  <li>
    <p>Finally, for \(E_{10}\):
\(E_{10} = \frac{10}{10} + E_9 = 1 + 28.29 \approx 29.29.\)</p>
  </li>
</ul>

<p>As discussed earlier, we must add 1 to account for our first step on the 11th node (from where we start exploring the remaining 10 nodes). Therefore,</p>

\[Ans = 1 + E_10 = 1 + 29.29 \approx 30.29.\]

<h3 id="thus-the-expected-number-of-steps-to-visit-all-11-nodes-at-least-once-is-approximately-3029-which-rounds-to-30-steps">Thus, the expected number of steps to visit all 11 nodes at least once is approximately <strong>30.29</strong>, which rounds to <strong>30</strong> steps.</h3>

<hr />

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Expectations" /><category term="Probability" /><category term="Problems" /><category term="Expectations" /><category term="Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Mean babysitter</title><link href="http://localhost:4000/combinatorics/statistics/problems/2025/03/21/Mean-babysitter.html" rel="alternate" type="text/html" title="Mean babysitter" /><published>2025-03-21T00:00:00+05:30</published><updated>2025-03-21T00:00:00+05:30</updated><id>http://localhost:4000/combinatorics/statistics/problems/2025/03/21/Mean-babysitter</id><content type="html" xml:base="http://localhost:4000/combinatorics/statistics/problems/2025/03/21/Mean-babysitter.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>10 kids are really hungry! Their babysitter has 12 units of food to give. However, she decides she only wants to give 4 of the children food. How many ways can she distribute the food units such that 6 of the children are hungry (receive no food), and the other 4 children receive at least 1 unit of food each?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/mean-babysitter">Click here</a></p>

<h2 id="solution">Solution</h2>

<h3 id="step-1-understanding-the-required-tasks">Step 1: Understanding the Required Tasks</h3>

<p>To distribute the food, we need to:</p>

<ol>
  <li>Choose 4 children who will receive food (equivalently, choose 6 children who won‚Äôt).</li>
  <li>Distribute 12 units of food among these 4 children, ensuring that each child gets at least 1 unit.</li>
</ol>

<h3 id="step-2-calculating-the-number-of-ways">Step 2: Calculating the Number of Ways</h3>

<h4 id="step-1-choosing-4-children"><strong>Step 1: Choosing 4 Children</strong></h4>
<p>Since we need to select 4 children out of 10, the number of ways to do this is:</p>

\[\binom{10}{4} = \binom{10}{6} = 210\]

<p>(since choosing 4 to receive food is the same as choosing 6 to not receive food).</p>

<h4 id="step-2-distributing-the-food"><strong>Step 2: Distributing the Food</strong></h4>
<p>Let the food received by the four chosen children be represented as:</p>

\[f_{a} + f_{b} + f_{c} + f_{d} = 12\]

<p>where \(f_{a}, f_{b}, f_{c}, f_{d}\) represent the food units received by each of the 4 children.</p>

<p>Since each child must get at least 1 unit, we make the substitution:</p>

\[f_{a} = 1 + x_{a}, \quad f_{b} = 1 + x_{b}, \quad f_{c} = 1 + x_{c}, \quad f_{d} = 1 + x_{d}\]

<p>Rewriting the equation:</p>

\[(1 + x_{a}) + (1 + x_{b}) + (1 + x_{c}) + (1 + x_{d}) = 12\]

<p>which simplifies to:</p>

\[x_{a} + x_{b} + x_{c} + x_{d} = 8\]

<p>This is now a classic ‚Äústars and bars‚Äù problem, where we distribute 8 extra food units among 4 children. The number of ways to do this is:</p>

\[\binom{8 + 4 - 1}{4 - 1} = \binom{11}{3} = 165\]

<h3 id="step-3-computing-the-final-answer">Step 3: Computing the Final Answer</h3>

<p>The total number of valid distributions is:</p>

\[\binom{10}{4} \times \binom{11}{3} = 210 \times 165 = 34,650\]

<h3 id="therefore-the-total-number-of-ways-is-mathbf34650">Therefore, the total number of ways is \(\mathbf{34650}\)</h3>
<hr />

<p>üí° Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Combinatorics" /><category term="Statistics" /><category term="Problems" /><category term="Combinatorics" /><category term="Counting" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Pass the ball</title><link href="http://localhost:4000/probability/statistics/problems/2025/03/18/Pass-the-Ball.html" rel="alternate" type="text/html" title="Pass the ball" /><published>2025-03-18T00:00:00+05:30</published><updated>2025-03-18T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/03/18/Pass-the-Ball</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/03/18/Pass-the-Ball.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>You and 4 other people are sitting in a circle. You are given a ball to start the game. Every second of this game, the person with the ball has three choices they can make. They can either pass the ball to the left, pass the ball to the right, or keep the ball (all with equal probability). This game goes on till someone keeps the ball. What is the probability that you are the person to end the game and keep the ball?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/pass-the-ball">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>Lets call the people \(A\)(me), \(B\), \(C\), \(D\), \(E\).
Note that \(B\) and \(E\) are symmetric (at distance 1)
Similarly, \(C\) and \(D\) are symmetric (at distance 2)</p>

<p>If one thinks through the question trivially, a simple approach could be to just ‚Äúcount‚Äù all possible ways the game ends at person A. But soon one realises there are inifinitely many ways, although possibly countable, but not-so-trivial after all!</p>

<p>A simpler approach involves identifying markov states and using conditional probabilities. The fundamental law of total probability states</p>

\[P(X) = \sum_{Y_i} P(X | Y_i) \times P(Y_i)\]

<h3 id="step-1-identifying-states">Step 1: Identifying States</h3>

<p>We can define 5 simple states, \(S_{A}\), \(S_{B}\), \(S_{C}\), \(S_{D}\), \(S_{E}\), with state \(S_{i}\) representing that the ball is with the \(i_{th}\) person.</p>

<p>Now, consider the probability that the ball is with person \(i\), and the game ends with person \(A\). Lets denote this as \(P(A* \mid i)\), where \(A*\) means that the game will end with person \(A\).</p>

<p>At each state, the person can either stop the game, or pass it on to its neighbours with equal probabilities! Lets try to form a set of equations in \(P(A* \mid i)\) using this.</p>

<h3 id="step-2-forming-the-set-of-probability-equations">Step 2: Forming the set of Probability equations</h3>

<p>For each state \(S_{i}\), lets represent \(P(A* \mid i)\) in terms of its neighbours.</p>

<p>Now,</p>

<p>For state \(S_{A}\) (i.e. the person \(A\) has the ball itself), I can either</p>
<ul>
  <li>Stop the game, with prob \(\frac{1}{3}\)</li>
  <li>Pass the ball to player \(B\), with prob \(\frac{1}{3}\), thus moving to state \(S_{B}\)</li>
  <li>Pass the ball to player \(E\), with prob \(\frac{1}{3}\), thus moving to state \(S_{E}\)</li>
</ul>

<p>Therefore, we can write</p>

\[P(A* \mid A) = \frac{1}{3} + P(A* \mid B)\frac{1}{3} + P(A* \mid E)\frac{1}{3}\]

<p>Note that here the first term represents \(A\) ending the game there itself.</p>

<p>Similarly, for state \(S_{B}\)</p>

\[P(A* \mid B) = P(A* \mid A)\frac{1}{3} + P(A* \mid C)\frac{1}{3}\]

<p>and for state \(S_{C}\)</p>

\[P(A* \mid C) = P(A* \mid B)\frac{1}{3} + P(A* \mid D)\frac{1}{3}\]

<blockquote>
  <p>For more intuition on how these equations are formed, think of it like ‚Äúthe probability that A ends the game, given that the ball is currently with C, is that either he passes the ball to B(first neighbour) and we compute this same probability for B, or that he passes on the ball to D(other neighbour), and we compute the same for D. Its somewhat ‚Äúrecursive‚Äù. For A, another possiblility (that I end the game right now) is added, leading to an extra \(\frac{1}{3}\)</p>
</blockquote>

<p>Now, lets utilize some symmetry!</p>

<p>Clearly, 
\(P(A* \mid C) = P(A* \mid D)\)
and \(P(A* \mid B) = P(A* \mid E)\)</p>

<p>(As C and D are symmetrically placed around A; same with B and E)</p>

<p>Thus, we can reduce the equations to 3 unique variables, \(P(A* \mid A)\), \(P(A* \mid B)\) and \(P(A* \mid C)\)</p>

<h3 id="step-3-solving-the-equations">Step 3: Solving the equations</h3>

<p>Now, substituting:</p>

\[a = P(A* \mid A)\]

\[b = P(A* \mid B) = P(A* \mid E)\]

\[a = P(A* \mid C) = P(A* \mid D)\]

<p>We get,</p>

\[a = \frac{1}{3} + \frac{2b}{3}\]

\[b = \frac{a + c}{3}\]

\[c = \frac{b + c}{3}\]

<p>Solving these, we get:</p>

\[a = \frac{5}{11}\]

<h3 id="therefore-the-probability-that-weperson-a-will-end-the-game-is-frac511">Therefore, the probability that we(Person \(A\)) will end the game is \(\frac{5}{11}\)</h3>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Conditional Probability" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Differ by 2</title><link href="http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2.html" rel="alternate" type="text/html" title="Differ by 2" /><published>2025-03-18T00:00:00+05:30</published><updated>2025-03-18T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>How many times do we have to roll a fair 6-sided die till we roll two numbers in a row that differ by 2?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/differ-by-2">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>Here, starting from the first roll, ofcourse each number is equally likely to show, with a probability of \(1/6\). Hypothetically, we could compute each possible suitable combination (1-3, 3-1, 2-4, 4-2 ‚Ä¶) and compute its probability. Summing this in the standard method of computing Expectation, we could get the answer, but clearly this method is very tedious, time-consuming and computationally heavy.</p>

<p>A better alternative is to use the concept of Conditional Expectations.
It essentially states that</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-identifying-states">Step 1: Identifying States</h3>

<p>In the described problem, the dice can show 6 possible faces. This means, we can identify 6 different unique states \(S_{1}\), \(S_{2}\), \(S_{3}\), \(S_{4}\), \(S_{5}\), \(S_{6}\).</p>

<p>This reduces our problem to a Markov Chain analysis, with transition probablities from each state to each other state as \(1/6\).</p>

<p>How? Essentially, each State \(S_{i}\) represents that the die showed i in the first roll. If I roll it again, then either the number will differ by 2 (leading to the simulation being stopped there), or it will show another number, and our analysis essentially ‚Äúresets‚Äù with a new number as our first number. (Ofcourse we will account for the fact that we did take 1 roll to each this new State).</p>

<p>We also note another interesting observation here.</p>

<p>I propose this - ‚ÄúThe expected no. of rolls for our problem, given that the first roll returned 1, is the same as the expected no. of rolls given that the first roll returned 6‚Äù</p>

<p>How? Simply because 1 and 6 are essentially symmetric. If I get 1 as my first roll, only 3 in the next roll would stop my simulation (Thus only 1 possible value will stop). Same goes for 6 (only 4 can fulfill the condition). Infact, same goes for 2 and 5!. If I get 2, only 4 can stop, and if I get 5, only 3 can stop my simulation.</p>

<p>Thus, \(E[X \mid 1] = E[X \mid 2] = E[X \mid 5] = E[X \mid 6]\), where \(E[X \mid i]\) represents the expected number of turns, given that the die started from face i.</p>

<p>As you may have guessed, we can do a similar analysis for \(E[X \mid 3]\) and \(E[X \mid 4]\). If my first roll gives 3, I have 2 possible cases (1 and 5) where my simulation ends in the next step. Same for if my first roll gives 4, because then either 2 or 6 will stop the simulation. Thus, by symmetry, 
\(E[X \mid 3] = E[X \mid 4]\).</p>

<p>Now, yet another fact!</p>

<p>Clearly, \(E[X] = 1/6 (1 + E[X \mid 1]) + 1/6 (1 + E[X \mid 2]) + 1/6 (1 + E[X \mid 3]) + 1/6 (1 + E[X \mid 4]) + 1/6 (1 + E[X \mid 5]) + 1/6 (1 + E[X \mid 5])\)</p>

<p>How? - Exercise to reader!</p>

<p>Thus, we can reduce the problem to</p>

<blockquote>
  <p>‚ÄúGiven the state transition probability 1/6 and the dependence between the states, find \(E[X \mid 1]... E[X \mid 6]\), where \(X\) is the event of getting 2 rolls differing by 2, and \(E[X \mid i]\) represents starting the experiment with face i‚Äù</p>
</blockquote>

<h3 id="step-2-forming-the-set-of-expectation-equations">Step 2: Forming the set of Expectation equations</h3>

<p>For each state \(i\), we compute \(E[X\mid i]\). But as discussed, since there is symmetry, it is sufficient to just compute \(E[X \mid 1]\) and \(E[X \mid 3]\).</p>

<p>Now,</p>

\[E[X \mid 1] = \frac{1}{6} (E[X \mid 1,1]) + \frac{1}{6} (E[X \mid 1,2]) + \frac{1}{6} (E[X \mid 1,3]) + \frac{1}{6} (E[X \mid 1,4]) + \frac{1}{6} (E[X \mid 1,5]) + \frac{1}{6} (E[X \mid 1,6])\]

<p>Substituting:</p>

<ul>
  <li>\(E[X \mid 1,3] = 1\) since rolling a 3 stops the process. (Thus only 1 step required till 3 from 1)</li>
  <li>\(E[X \mid 1,j] = 1 + E[X \mid j]\) for all other \(j\), since the process resets but after one step.</li>
</ul>

<p>Thus,</p>

\[E[X \mid 1] = \frac{1}{6} (1 + E[X \mid 1]) + \frac{1}{6} (1 + E[X \mid 2]) + \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 4]) + \frac{1}{6} (1 + E[X \mid 5]) + \frac{1}{6} (1 + E[X \mid 6])\]

<p>Similarly, for \(E[X \mid 3]\):</p>

\[E[X \mid 3] = \frac{1}{6} (E[X \mid 3,1]) + \frac{1}{6} (E[X \mid 3,2]) + \frac{1}{6} (E[X \mid 3,3]) + \frac{1}{6} (E[X \mid 3,4]) + \frac{1}{6} (E[X \mid 3,5]) + \frac{1}{6} (E[X \mid 3,6])\]

<p>Substituting:</p>

<ul>
  <li>\(E[X \mid 3,1] = 1\), since rolling a 1 stops the process.</li>
  <li>\(E[X \mid 3,5] = 1\), since rolling a 5 stops the process.</li>
  <li>\(E[X \mid 3,j] = 1 + E[X \mid j]\) for all other \(j\).</li>
</ul>

<p>Thus,</p>

\[E[X \mid 3] = \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 2]) + \frac{1}{6} (1 + E[X \mid 3]) + \frac{1}{6} (1 + E[X \mid 4]) + \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 6])\]

<h3 id="step-3-solving-the-equations">Step 3: Solving the equations</h3>

<p>Now, using:</p>

\[a = E[X \mid 1] = E[X \mid 2] = E[X \mid 5] = E[X \mid 6]\]

\[b = E[X \mid 3] = E[X \mid 4]\]

<p>Substitute these into the equations made above, and simplify, to get:</p>

\[a = 1 + \frac{1}{6} (a + a + b + a + a)\]

\[b = 1 + \frac{1}{6} (a + a + b + b)\]

<p>Solving these, we get:</p>

\[a = 5, \quad b = 4\]

<p>Finally, computing \(E[X]\):</p>

\[E[X] = 1 + \frac{1}{6} (a + a + b + b + a + a) = 1 + \frac{4a + 2b}{6}\]

\[E[X] = 1 + \frac{4 \times 5 + 2 \times 4}{6} = 1 + \frac{14}{3}\]

\[E[X] = \frac{17}{3}\]

<h3 id="therefore-the-expected-number-of-moves-required-for-the-ant-to-reach-back-to-its-starting-point-is-frac173">Therefore, the expected number of moves required for the ant to reach back to its starting point is \(\frac{17}{3}\)</h3>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Confused Ant II</title><link href="http://localhost:4000/probability/statistics/problems/2025/03/17/Confused-Ant-II.html" rel="alternate" type="text/html" title="Confused Ant II" /><published>2025-03-17T00:00:00+05:30</published><updated>2025-03-17T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/03/17/Confused-Ant-II</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/03/17/Confused-Ant-II.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>An ant walks the corner of a 3D cube and moves to one of the three adjacent vertices with equal probability at each step. Find the expected number of steps needed for the ant to return to the vertex it started at.</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/confused-ant-ii">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>Here from each corner, the ant can take any path with an equal probability of \(1/3\).
We must realize that if we compute the probability of each possible path, and multiply it by the number of steps its taking, and take its summation over all possible cases, that would yes lead to our answer, but it is very tedious to compute.</p>

<p>A better alternative is to use the concept of Conditional Expectations.
It essentially states that</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-identifying-states">Step 1: Identifying States</h3>

<p>In the described problem, the ant can be uniquely at 4 possible positions.</p>
<ol>
  <li>At the starting point itself (call this \(A\)).</li>
  <li>At a point only 1 edge away from \(A\) (call this \(B\)).</li>
  <li>At a point 2 edges away from \(A\) (call this \(C\)).</li>
  <li>At a point 3 edges away from \(A\) (call this \(D\). Note that there is only 1 such point, the one diagonally opposite to \(A\)).</li>
</ol>

<p>This reduces our problem to a Markov Chain analysis, with transition probablities as follows -</p>

<p>State \(A\) to State \(B\) = 1 
(How? -&gt; Note that from \(A\), you have 3 options to move, all symmetric and 1 edge away from \(A\). This means you will definitely move to state \(B\))</p>

<p>State \(B\) to State \(A\) = 1/3
(How? -&gt; When you are at point \(B\) (which is 1 edge away from \(A\)), you can move back to point \(A\) with probability 1/3 (since at each point, all edges are equiprobable))</p>

<p>State \(B\) to State \(C\) = 2/3
(How? From State \(B\), you either move back to \(A\), or the other 2 edges lead to a point which is 2 edges away from \(A\), this point \(C\))</p>

<p>State \(C\) to State \(B\) = 2/3
(How? When at State \(C\), 2 paths will lead to State \(B\), and 1 will lead to \(D\). Try to visualize this on a cube, with State \(C\) being just adjacent to the opposite corner to \(A\))</p>

<p>State \(C\) to State \(D\) = 1/3
(How? When at State \(C\), 2 paths will lead to State \(B\), and 1 will lead to \(D\))</p>

<p>Thus, we can reduce the problem to</p>

<blockquote>
  <p>‚ÄúGiven the above State Transition Probabilities, find E[A], where A is the event of returning to point A after moving atleast once‚Äù</p>
</blockquote>

<h3 id="step-2-forming-the-set-of-expectation-equations">Step 2: Forming the set of Expectation equations</h3>

<p>For any State X, using the Conditional Expectation Equation described above</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<p>Where the states \(Y_i\) represent points just adjacent to state \(X\).</p>

<p>Solving for State A, we get</p>

<p>\(E[A] = 1\)(for the 1 step we take) \(+3*1/3E[B]\)
Where \(E(B)\) represents the expected value to reach state \(A\) from \(B\).</p>

<p>Simplifying, we get</p>

\[E[A] = 1 + E[B]\]

<p>Similarly, for State \(B\), we have,</p>

<p>Neighbouring States = A, C, C. Thus,</p>

\[E[B] = 1 +  1/3(E'[A]) + 2/3(E[C])\]

<p>Note that here, \(E'[A]\) is NOT \(E[A]\).</p>

<p>\(E[A]\) is the expected number of states to reach \(A\) from \(A\), given that we haven‚Äôt moved before.</p>

<p>\(E'[A]\) is the expected number of states to reach \(A\) from \(A\), given that we HAVE moved (since we went to \(B\)!). This is obviously 0, as you have already reached \(A\)!</p>

<p>Thus, we get</p>

\[E[B] = 1 + 2/3 (E[C])\]

<p>For states \(C\) and \(D\), following a similar analysis, we will get</p>

\[E[C] = 1 + 1/3 (E[D]) + 2/3 (E[B])\]

<p>(Note - for \(C\), we are surrounded by 2 \(B\)‚Äôs and 1 \(D\)); and</p>

\[E[D] = 1 + E[C]\]

<p>(When at \(D\), we are only surrounded by \(C\)‚Äôs. Just a reminder, \(D\) is the opposite diagonal to \(A\)(our starting point), so this becomes trivial)</p>

<p>Therefore, we have a set of 4 equations and four variables (\(E[A]\), \(E[B]\), \(E[C]\), \(E[D]\))! These can be solved easily using backsubstitution.</p>

<h3 id="step-3-solving-the-equations">Step 3: Solving the Equations</h3>

<p>We have the following system of equations:</p>

<ol>
  <li>
\[E[A] = 1 + E[B]\]
  </li>
  <li>
\[E[B] = 1 + \frac{2}{3} E[C]\]
  </li>
  <li>
\[E[C] = 1 + \frac{1}{3} E[D] + \frac{2}{3} E[B]\]
  </li>
  <li>
\[E[D] = 1 + E[C]\]
  </li>
</ol>

<p>Now,</p>

<p>From Equation (4):</p>

\[E[D] = 1 + E[C]\]

<p>Substituting this into Equation (3):</p>

\[E[C] = 1 + \frac{1}{3} (1 + E[C]) + \frac{2}{3} E[B]\]

<p>Expanding:</p>

\[E[C] = 1 + \frac{1}{3} + \frac{1}{3}E[C] + \frac{2}{3}E[B]\]

<p>Rearrange:</p>

\[E[C] - \frac{1}{3} E[C] = \frac{4}{3} + \frac{2}{3}E[B]\]

\[\frac{2}{3}E[C] = \frac{4}{3} + \frac{2}{3}E[B]\]

<p>Multiplying both sides by \(\frac{3}{2}\):</p>

\[E[C] = 2 + E[B]\]

<p>From Equation (2):</p>

\[E[B] = 1 + \frac{2}{3} E[C]\]

<p>Substituting \(E[C] = 2 + E[B]\):</p>

\[E[B] = 1 + \frac{2}{3} (2 + E[B])\]

\[E[B] = 1 + \frac{4}{3} + \frac{2}{3}E[B]\]

\[E[B] - \frac{2}{3}E[B] = \frac{7}{3}\]

\[\frac{1}{3}E[B] = \frac{7}{3}\]

\[E[B] = 7\]

<p>Thus, finally we get,</p>

\[E[A] = 1 + E[B] = 1 + 7 = 8\]

<h3 id="therefore-the-the-expected-number-of-moves-required-for-the-ant-to-reach-back-to-its-starting-point-is-8">Therefore, the the expected number of moves required for the ant to reach back to its starting point is 8.</h3>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry></feed>