<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-18T18:29:17+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">JXTech</title><subtitle>Advanced probability problems and detailed solutions</subtitle><author><name>JXTech</name></author><entry><title type="html">Differ by 2</title><link href="http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2.html" rel="alternate" type="text/html" title="Differ by 2" /><published>2025-03-18T00:00:00+05:30</published><updated>2025-03-18T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/03/18/Differ-by-2.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>How many times do we have to roll a fair 6-sided die till we roll two numbers in a row that differ by 2?</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/differ-by-2">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>Here, starting from the first roll, ofcourse each number is equally likely to show, with a probability of \(1/6\). Hypothetically, we could compute each possible suitable combination (1-3, 3-1, 2-4, 4-2 ‚Ä¶) and compute its probability. Summing this in the standard method of computing Expectation, we could get the answer, but clearly this method is very tedious, time-consuming and computationally heavy.</p>

<p>A better alternative is to use the concept of Conditional Expectations.
It essentially states that</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-identifying-states">Step 1: Identifying States</h3>

<p>In the described problem, the dice can show 6 possible faces. This means, we can identify 6 different unique states \(S_{1}\), \(S_{2}\), \(S_{3}\), \(S_{4}\), \(S_{5}\), \(S_{6}\).</p>

<p>This reduces our problem to a Markov Chain analysis, with transition probablities from each state to each other state as \(1/6\).</p>

<p>How? Essentially, each State \(S_{i}\) represents that the die showed i in the first roll. If I roll it again, then either the number will differ by 2 (leading to the simulation being stopped there), or it will show another number, and our analysis essentially ‚Äúresets‚Äù with a new number as our first number. (Ofcourse we will account for the fact that we did take 1 roll to each this new State).</p>

<p>We also note another interesting observation here.</p>

<p>I propose this - ‚ÄúThe expected no. of rolls for our problem, given that the first roll returned 1, is the same as the expected no. of rolls given that the first roll returned 6‚Äù</p>

<p>How? Simply because 1 and 6 are essentially symmetric. If I get 1 as my first roll, only 3 in the next roll would stop my simulation (Thus only 1 possible value will stop). Same goes for 6 (only 4 can fulfill the condition). Infact, same goes for 2 and 5!. If I get 2, only 4 can stop, and if I get 5, only 3 can stop my simulation.</p>

<p>Thus, \(E[X \mid 1] = E[X \mid 2] = E[X \mid 5] = E[X \mid 6]\), where \(E[X \mid i]\) represents the expected number of turns, given that the die started from face i.</p>

<p>As you may have guessed, we can do a similar analysis for \(E[X \mid 3]\) and \(E[X \mid 4]\). If my first roll gives 3, I have 2 possible cases (1 and 5) where my simulation ends in the next step. Same for if my first roll gives 4, because then either 2 or 6 will stop the simulation. Thus, by symmetry, 
\(E[X \mid 3] = E[X \mid 4]\).</p>

<p>Now, yet another fact!</p>

<p>Clearly, \(E[X] = 1/6 (1 + E[X \mid 1]) + 1/6 (1 + E[X \mid 2]) + 1/6 (1 + E[X \mid 3]) + 1/6 (1 + E[X \mid 4]) + 1/6 (1 + E[X \mid 5]) + 1/6 (1 + E[X \mid 5])\)</p>

<p>How? - Exercise to reader!</p>

<p>Thus, we can reduce the problem to</p>

<blockquote>
  <p>‚ÄúGiven the state transition probability 1/6 and the dependence between the states, find \(E[X \mid 1]... E[X \mid 6]\), where \(X\) is the event of getting 2 rolls differing by 2, and \(E[X \mid i]\) represents starting the experiment with face i‚Äù</p>
</blockquote>

<h3 id="step-2-forming-the-set-of-expectation-equations">Step 2: Forming the set of Expectation equations</h3>

<p>For each state \(i\), we compute \(E[X\mid i]\). But as discussed, since there is symmetry, it is sufficient to just compute \(E[X \mid 1]\) and \(E[X \mid 3]\).</p>

<p>Now,</p>

\[E[X \mid 1] = \frac{1}{6} (E[X \mid 1,1]) + \frac{1}{6} (E[X \mid 1,2]) + \frac{1}{6} (E[X \mid 1,3]) + \frac{1}{6} (E[X \mid 1,4]) + \frac{1}{6} (E[X \mid 1,5]) + \frac{1}{6} (E[X \mid 1,6])\]

<p>Substituting:</p>

<ul>
  <li>\(E[X \mid 1,3] = 1\) since rolling a 3 stops the process. (Thus only 1 step required till 3 from 1)</li>
  <li>\(E[X \mid 1,j] = 1 + E[X \mid j]\) for all other \(j\), since the process resets but after one step.</li>
</ul>

<p>Thus,</p>

\[E[X \mid 1] = \frac{1}{6} (1 + E[X \mid 1]) + \frac{1}{6} (1 + E[X \mid 2]) + \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 4]) + \frac{1}{6} (1 + E[X \mid 5]) + \frac{1}{6} (1 + E[X \mid 6])\]

<p>Similarly, for \(E[X \mid 3]\):</p>

\[E[X \mid 3] = \frac{1}{6} (E[X \mid 3,1]) + \frac{1}{6} (E[X \mid 3,2]) + \frac{1}{6} (E[X \mid 3,3]) + \frac{1}{6} (E[X \mid 3,4]) + \frac{1}{6} (E[X \mid 3,5]) + \frac{1}{6} (E[X \mid 3,6])\]

<p>Substituting:</p>

<ul>
  <li>\(E[X \mid 3,1] = 1\), since rolling a 1 stops the process.</li>
  <li>\(E[X \mid 3,5] = 1\), since rolling a 5 stops the process.</li>
  <li>\(E[X \mid 3,j] = 1 + E[X \mid j]\) for all other \(j\).</li>
</ul>

<p>Thus,</p>

\[E[X \mid 3] = \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 2]) + \frac{1}{6} (1 + E[X \mid 3]) + \frac{1}{6} (1 + E[X \mid 4]) + \frac{1}{6} (1) + \frac{1}{6} (1 + E[X \mid 6])\]

<h3 id="step-3-solving-the-equations">Step 3: Solving the equations</h3>

<p>Now, using:</p>

\[a = E[X \mid 1] = E[X \mid 2] = E[X \mid 5] = E[X \mid 6]\]

\[b = E[X \mid 3] = E[X \mid 4]\]

<p>Substitute these into the equations made above, and simplify, to get:</p>

\[a = 1 + \frac{1}{6} (a + a + b + a + a)\]

\[b = 1 + \frac{1}{6} (a + a + b + b)\]

<p>Solving these, we get:</p>

\[a = 5, \quad b = 4\]

<p>Finally, computing \(E[X]\):</p>

\[E[X] = 1 + \frac{1}{6} (a + a + b + b + a + a) = 1 + \frac{4a + 2b}{6}\]

\[E[X] = 1 + \frac{4 \times 5 + 2 \times 4}{6} = 1 + \frac{14}{3}\]

\[E[X] = \frac{17}{3}\]

<h3 id="therefore-the-the-expected-number-of-moves-required-for-the-ant-to-reach-back-to-its-starting-point-is-frac173">Therefore, the the expected number of moves required for the ant to reach back to its starting point is \(\frac{17}{3}\)</h3>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Confused Ant II</title><link href="http://localhost:4000/probability/statistics/problems/2025/03/17/Confused-Ant-II.html" rel="alternate" type="text/html" title="Confused Ant II" /><published>2025-03-17T00:00:00+05:30</published><updated>2025-03-17T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/03/17/Confused-Ant-II</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/03/17/Confused-Ant-II.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>An ant walks the corner of a 3D cube and moves to one of the three adjacent vertices with equal probability at each step. Find the expected number of steps needed for the ant to return to the vertex it started at.</p>

<p><strong>Original Problem Link</strong>: <a href="https://www.quantguide.io/questions/confused-ant-ii">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>Here from each corner, the ant can take any path with an equal probability of \(1/3\).
We must realize that if we compute the probability of each possible path, and multiply it by the number of steps its taking, and take its summation over all possible cases, that would yes lead to our answer, but it is very tedious to compute.</p>

<p>A better alternative is to use the concept of Conditional Expectations.
It essentially states that</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<h3 id="step-1-identifying-states">Step 1: Identifying States</h3>

<p>In the described problem, the ant can be uniquely at 4 possible positions.</p>
<ol>
  <li>At the starting point itself (call this \(A\)).</li>
  <li>At a point only 1 edge away from \(A\) (call this \(B\)).</li>
  <li>At a point 2 edges away from \(A\) (call this \(C\)).</li>
  <li>At a point 3 edges away from \(A\) (call this \(D\). Note that there is only 1 such point, the one diagonally opposite to \(A\)).</li>
</ol>

<p>This reduces our problem to a Markov Chain analysis, with transition probablities as follows -</p>

<p>State \(A\) to State \(B\) = 1 
(How? -&gt; Note that from \(A\), you have 3 options to move, all symmetric and 1 edge away from \(A\). This means you will definitely move to state \(B\))</p>

<p>State \(B\) to State \(A\) = 1/3
(How? -&gt; When you are at point \(B\) (which is 1 edge away from \(A\)), you can move back to point \(A\) with probability 1/3 (since at each point, all edges are equiprobable))</p>

<p>State \(B\) to State \(C\) = 2/3
(How? From State \(B\), you either move back to \(A\), or the other 2 edges lead to a point which is 2 edges away from \(A\), this point \(C\))</p>

<p>State \(C\) to State \(B\) = 2/3
(How? When at State \(C\), 2 paths will lead to State \(B\), and 1 will lead to \(D\). Try to visualize this on a cube, with State \(C\) being just adjacent to the opposite corner to \(A\))</p>

<p>State \(C\) to State \(D\) = 1/3
(How? When at State \(C\), 2 paths will lead to State \(B\), and 1 will lead to \(D\))</p>

<p>Thus, we can reduce the problem to</p>

<blockquote>
  <p>‚ÄúGiven the above State Transition Probabilities, find E[A], where A is the event of returning to point A after moving atleast once‚Äù</p>
</blockquote>

<h3 id="step-2-forming-the-set-of-expectation-equations">Step 2: Forming the set of Expectation equations</h3>

<p>For any State X, using the Conditional Expectation Equation described above</p>

\[E[X] = \sum_{Y_i} E[X \mid Y_i] P(Y_i)\]

<p>Where the states \(Y_i\) represent points just adjacent to state \(X\).</p>

<p>Solving for State A, we get</p>

<p>\(E[A] = 1\)(for the 1 step we take) \(+3*1/3E[B]\)
Where \(E(B)\) represents the expected value to reach state \(A\) from \(B\).</p>

<p>Simplifying, we get</p>

\[E[A] = 1 + E[B]\]

<p>Similarly, for State \(B\), we have,</p>

<p>Neighbouring States = A, C, C. Thus,</p>

\[E[B] = 1 +  1/3(E'[A]) + 2/3(E[C])\]

<p>Note that here, \(E'[A]\) is NOT \(E[A]\).</p>

<p>\(E[A]\) is the expected number of states to reach \(A\) from \(A\), given that we haven‚Äôt moved before.</p>

<p>\(E'[A]\) is the expected number of states to reach \(A\) from \(A\), given that we HAVE moved (since we went to \(B\)!). This is obviously 0, as you have already reached \(A\)!</p>

<p>Thus, we get</p>

\[E[B] = 1 + 2/3 (E[C])\]

<p>For states \(C\) and \(D\), following a similar analysis, we will get</p>

\[E[C] = 1 + 1/3 (E[D]) + 2/3 (E[B])\]

<p>(Note - for \(C\), we are surrounded by 2 \(B\)‚Äôs and 1 \(D\)); and</p>

\[E[D] = 1 + E[C]\]

<p>(When at \(D\), we are only surrounded by \(C\)‚Äôs. Just a reminder, \(D\) is the opposite diagonal to \(A\)(our starting point), so this becomes trivial)</p>

<p>Therefore, we have a set of 4 equations and four variables (\(E[A]\), \(E[B]\), \(E[C]\), \(E[D]\))! These can be solved easily using backsubstitution.</p>

<h3 id="step-3-solving-the-equations">Step 3: Solving the Equations</h3>

<p>We have the following system of equations:</p>

<ol>
  <li>
\[E[A] = 1 + E[B]\]
  </li>
  <li>
\[E[B] = 1 + \frac{2}{3} E[C]\]
  </li>
  <li>
\[E[C] = 1 + \frac{1}{3} E[D] + \frac{2}{3} E[B]\]
  </li>
  <li>
\[E[D] = 1 + E[C]\]
  </li>
</ol>

<p>Now,</p>

<p>From Equation (4):</p>

\[E[D] = 1 + E[C]\]

<p>Substituting this into Equation (3):</p>

\[E[C] = 1 + \frac{1}{3} (1 + E[C]) + \frac{2}{3} E[B]\]

<p>Expanding:</p>

\[E[C] = 1 + \frac{1}{3} + \frac{1}{3}E[C] + \frac{2}{3}E[B]\]

<p>Rearrange:</p>

\[E[C] - \frac{1}{3} E[C] = \frac{4}{3} + \frac{2}{3}E[B]\]

\[\frac{2}{3}E[C] = \frac{4}{3} + \frac{2}{3}E[B]\]

<p>Multiplying both sides by \(\frac{3}{2}\):</p>

\[E[C] = 2 + E[B]\]

<p>From Equation (2):</p>

\[E[B] = 1 + \frac{2}{3} E[C]\]

<p>Substituting \(E[C] = 2 + E[B]\):</p>

\[E[B] = 1 + \frac{2}{3} (2 + E[B])\]

\[E[B] = 1 + \frac{4}{3} + \frac{2}{3}E[B]\]

\[E[B] - \frac{2}{3}E[B] = \frac{7}{3}\]

\[\frac{1}{3}E[B] = \frac{7}{3}\]

\[E[B] = 7\]

<p>Thus, finally we get,</p>

\[E[A] = 1 + E[B] = 1 + 7 = 8\]

<h3 id="therefore-the-the-expected-number-of-moves-required-for-the-ant-to-reach-back-to-its-starting-point-is-8">Therefore, the the expected number of moves required for the ant to reach back to its starting point is 8.</h3>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Expectations" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Random Ratio</title><link href="http://localhost:4000/probability/statistics/problems/2025/02/27/Random-Ratio.html" rel="alternate" type="text/html" title="Random Ratio" /><published>2025-02-27T00:00:00+05:30</published><updated>2025-02-27T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/02/27/Random-Ratio</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/02/27/Random-Ratio.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>\(p\) and \(q\) are two points chosen at random between 0 \(\&amp;\) 1. What is the probability that the ratio \(p/q\) lies between 1 \(\&amp;\) 2?</p>

<p><strong>Original Problem Link</strong>: <a href="https://brainstellar.com/puzzles/medium/112">Click here</a></p>

<h2 id="solution">Solution</h2>

<p>We have 2 random variables (RVs) \(p \&amp; q\) here. Let‚Äôs try to fix one for simplicity, and then use that result to develop a general solution where both are RVs.</p>

<h3 id="step-1-fixing-q">Step 1: Fixing q</h3>

<p>Say we fix \(q\) at some value between 0 and 1. Now, the given problem reduces to:</p>

<blockquote>
  <p>‚Äúq is a fixed value between 0 and 1. p ~ Uniform(0,1). What is the probability that 1 &lt; p/q &lt; 2?‚Äù</p>
</blockquote>

<p>This question is fairly straightforward.</p>

<h3 id="step-2-rearranging-the-inequality">Step 2: Rearranging the Inequality</h3>

<p>Let‚Äôs rearrange the inequality:</p>

\[1 &lt; \frac{p}{q} &lt; 2\]

\[q &lt; p &lt; 2q\]

<p>Also, note that since p is restricted in (0,1), we must say:</p>

\[\max(0,q) &lt; p &lt; \min(2q, 1)\]

<p>But since q is also restricted in (0,1), we have \(\max(0,q) = q\)</p>

<p>Thus, the final expression is:</p>

\[q &lt; p &lt; \min(2q,1)\]

<h3 id="step-3-computing-the-probability">Step 3: Computing the Probability</h3>

<p>Now, let‚Äôs compute the probability that p will lie within this range.</p>

<p>As \(p \sim \text{Uniform}(0,1)\), the required probability:</p>

\[P = \frac{\min(1,2q) - q}{1} = \min(2q,1) - q\]

<p>(Note: The probability is simply the length of the required range divided by the length of the total range. This is also visible by intuition)</p>

<h3 id="step-4-considering-q-as-a-random-variable">Step 4: Considering q as a Random Variable</h3>

<p>Now, note that this is the case when q is fixed. But q itself will vary from 0 to 1.</p>

<p>We can write the above probability as ‚Äúconditioned on‚Äù a particular q:</p>

\[P(E|q) = \min(2q,1) - q\]

<p>(Where E is our required event of \(1 &lt; \frac{p}{q} &lt; 2\))</p>

<h3 id="step-5-using-the-law-of-total-probability">Step 5: Using the Law of Total Probability</h3>

<p>Using fundamental laws, we have:</p>

\[P(E) = \sum P(E|q)P(q)\]

<p>What is P(q)? Essentially the probability of choosing a particular value from 0 to 1, an infinite set! Clearly very small! Let‚Äôs use calculus to denote this.</p>

\[P(q) = \frac{dq}{1} = dq\]

<p>Thus,</p>

\[P(E) = \int_0^1 (\min(2q,1) - q) \, dq\]

<h3 id="step-6-solving-the-integral">Step 6: Solving the Integral</h3>

<p>To solve this integral, we need to split it into two parts:</p>

<ol>
  <li>From 0 to 1/2, where \(\min(2q,1) = 2q\)</li>
  <li>From 1/2 to 1, where \(\min(2q,1) = 1\)</li>
</ol>

<p>Now,</p>

\[P(E) = \int_0^{1/2} (2q - q) \, dq + \int_{1/2}^1 (1 - q) \,\]

\[= \int_0^{1/2} q \, dq + \int_{1/2}^1 (1 - q) \, dq\]

\[= [\frac{q^2}{2}]_0^{1/2} + [q - \frac{q^2}{2}]_{1/2}^1\]

\[= (\frac{1}{8} - 0) + ((1 - \frac{1}{2}) - (\frac{1}{2} - \frac{1}{8}))\]

\[= \frac{1}{8} + \frac{1}{2} - \frac{3}{8} = \frac{1}{4}\]

<h3 id="therefore-the-probability-that-the-ratio-pq-lies-between-1-and-2-is-frac14-or-025-or-25">Therefore, the probability that the ratio \(p/q\) lies between 1 and 2 is \(\frac{1}{4}\) or \(0.25\) or \(25\%\).</h3>

<hr />

<p>PS - A similar integration is involved in the problem <a href="https://jxtech-s.github.io/probability/statistics/problems/2025/02/23/Random-Angle-II.html">Random-Angle-II</a>. Check it out for a more detailed explaination incase of any confusions!.</p>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Integration" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Intersecting Chords</title><link href="http://localhost:4000/probability/statistics/problems/2025/02/26/Intersecting-Chords.html" rel="alternate" type="text/html" title="Intersecting Chords" /><published>2025-02-26T00:00:00+05:30</published><updated>2025-02-26T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/02/26/Intersecting-Chords</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/02/26/Intersecting-Chords.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>10 chords with uniformly randomly chosen endpoints are drawn on a circle. What is the expected number of intersections?</p>

<p><strong>Original Problem Link:</strong> <a href="https://www.quantguide.io/questions/intersecting-chords">Click here</a></p>

<hr />

<h2 id="solution">Solution</h2>

<p>Let us consider the simpler case of 2 chords intersecting. Once we have that, perhaps we can use it to formulate something for 10 chords.</p>

<p>Now, focusing on the subproblem:</p>
<blockquote>
  <p>I draw 2 chords in a circle at random, what is the probability that they intersect? Equivalently, what is the expected number of intersections?</p>
</blockquote>

<p>To solve this, there exist two fundamental approaches.</p>

<h3 id="approach-1---complicated-stuff-alert">Approach 1 - [Complicated stuff alert]</h3>

<p>One is a rigorous mathematical treatment, which involves considering that a random chord drawn in a circle will be defined by 2 angles (say \(\theta_1\) and \(\theta_2\)), where these angles define the start and the endpoint of the chord with respect to a given reference radius. Both these angles will have a uniform \((0, 2\pi)\) distribution.</p>

<p>Thus, the angle made by the chord towards the circumference will be \((\theta_1 - \theta_2)\), which will have a triangular distribution. Once this is computed, we must calculate:</p>

\[2 \times \frac{\theta}{2\pi} \times \left( 1 - \frac{\theta}{2\pi} \right)\]

<p>and integrate over all \(\theta\) to compute the required probability.</p>

<p>How did this expression come?<br />
Given a chord, to make another intersecting chord, I can choose any random point from one ‚Äúside‚Äù of the chord, and another from the other ‚Äúside.‚Äù</p>

<p>Note that the probability of choosing a point from one ‚Äúside‚Äù is \(\frac{\theta}{2\pi}\), where \(\theta\) is the angle from the center subtended by the chord in that side. Also, the ‚Äú2‚Äù in the start is added because the ordering of points is unique. (As in, either I choose one end from side A, other from side B, or one end from side B, and other from side A) (Here side A and B mean different sides of the chord (one is subtending angle \(\theta\), other is subtending \(2\pi - \theta\)))</p>

<p>Clearly, this approach is a bit brain-racking (but it works; I have manually calculated and verified the answer. If interested, feel free to hit me up, and we can discuss this further!).</p>

<h3 id="a-simpler-approach">A Simpler Approach</h3>

<p>Clearly, 2 chords drawn randomly are essentially defined by 4 points chosen at random on a circle. Say \(A, B, C, D\).</p>

<p>Now, let‚Äôs think of how we can connect these points such that the chords intersect. To connect them, these 3 arrangements are possible:</p>

<ol>
  <li>\(A\)-\(B\), \(C\)-\(D\)</li>
  <li>\(A\)-\(C\), \(B\)-\(D\)</li>
  <li>\(A\)-\(D\), \(B\)-\(C\)</li>
</ol>

<p>Note that out of the 3, only arrangement (2) will result in an intersection. Since everything here is uniformly random, all arrangements are equally likely, hence the probability of intersection is \(\frac{1}{3}\).</p>

<p>Thus, we have now fairly established that the probability of intersection of 2 chords drawn at random in a circle is \(\frac{1}{3}\). (Read up the above explanation again, it may take time to digest).</p>

<hr />

<h3 id="moving-on-to-the-original-problem-what-if-we-have-10-chords">Moving on to the original problem. What if we have 10 chords?</h3>

<p>It‚Äôs actually fairly simple. From the 10 chords, select any 2 at random. What is the probability they will intersect? \(\frac{1}{3}\), right? (As we computed above).</p>

<p>This means every pair will essentially contribute \(\frac{1}{3}\) to the expected number of intersections. (Note that the probability of overlapping intersections, i.e., more than 2 chords intersecting at the same point, is VERY small).</p>

<p>Now, in how many ways can we select 2 chords at random from 10?</p>

\[\binom{10}{2} = \frac{10 \times 9}{2}\]

<p>Thus, the expected number of intersections in the case of 10 chords will be:</p>

\[\binom{10}{2} \times \frac{1}{3} = \frac{10 \times 9}{2 \times 3} = 15.\]

<hr />

<h3 id="therefore-the-answer-is-15-intersections">Therefore, the answer is <strong>15</strong> intersections.</h3>

<p><em>(PS: On the website linked above, it shows incorrect for ‚Äú15.‚Äù One must enter ‚Äú45/3‚Äù instead. A weird error, tbh. Possibly because 10C2 is 45, and p(for 2 chords) = 1/3, Thus 45/3)</em></p>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Combinatorics" /><category term="Counting Principle" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Breaking Stick</title><link href="http://localhost:4000/probability/statistics/problems/2025/02/24/Breaking-Sticks.html" rel="alternate" type="text/html" title="Breaking Stick" /><published>2025-02-24T00:00:00+05:30</published><updated>2025-02-24T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/02/24/Breaking-Sticks</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/02/24/Breaking-Sticks.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>
<p>A stick of length L drops and breaks at a random point distributed uniformly across the length.<br />
What is the expected length of the smaller part?</p>

<p>Original Problem Link:  <a href="https://brainstellar.com/puzzles/medium/119">Click here</a></p>

<hr />

<h2 id="solution">Solution</h2>

<p>As given in the question, the point where the stick will break is uniformly random.</p>

<p>Now, lets consider, what is the probability, that a particular element (very small) point will be chosen (which is at a distance \(x\) from one end)?</p>

<p>Very small, right? Yes!</p>

<p>We must quantify this using calculus.</p>

<p>We can say that the probability will be:</p>

\[\frac{dx}{L}\]

<p>where \(L\) is the length of the rod.</p>

<p>Now, if this is the case, then the rod will break into 2 parts, one with length \(x\), other with \(L-x\).</p>

<p>Using the fundamental definition of Expectation, we can say that</p>

\[E[l] = \sum (l.P(l)), \quad l \text{ varies from } 0 \text{ to } \frac{L}{2}\]

<p>(as we are looking at the smaller edge)</p>

<p>Here, \(P(l)\) is:</p>

\[\frac{dl}{L}, \quad \text{right? No!}\]

<p>\(P(l)\) means what‚Äôs the probability that the smaller part will have a length \(l\).</p>

<p>Note that there are 2 points where a rod can break, for the smaller length to be a particular \(l\)<br />
(One is at \(l\) distance from one end, the other is at \(l\) distance from the other end).</p>

<p>Thus,</p>

\[P(l) = \frac{2 \, dl}{L}\]

<p>Now, the sigma becomes an integration as we have elemental quantities involved.</p>

<p>Evaluating the integral, we get</p>

\[E[l] = \int_0^{L/2} l \cdot \frac{2 \, dl}{L}\]

\[= \frac{2}{L} \int_0^{L/2} l \, dl\]

\[= \frac{2}{L} \times \left[ \frac{l^2}{2} \right]_0^{L/2}\]

\[= \frac{2}{L} \times \frac{(L/2)^2}{2}\]

\[= \frac{2}{L} \times \frac{L^2}{8}\]

\[= \frac{L}{4}\]

<h3 id="final-answer">Final Answer</h3>

<p>Thus, the expected length of the smaller part is:</p>

\[\boxed{\frac{L}{4}}\]

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Uniform Distribution" /><category term="Integration" /><summary type="html"><![CDATA[Problem Statement A stick of length L drops and breaks at a random point distributed uniformly across the length. What is the expected length of the smaller part?]]></summary></entry><entry><title type="html">Chess Tournament I</title><link href="http://localhost:4000/probability/statistics/problems/2025/02/23/Chess-Tournament-I.html" rel="alternate" type="text/html" title="Chess Tournament I" /><published>2025-02-23T00:00:00+05:30</published><updated>2025-02-23T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/02/23/Chess-Tournament-I</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/02/23/Chess-Tournament-I.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>A chess tournament has 128 players, each with a  distinct  rating. Assume that the player with the  higher rating always wins  against a lower rated opponent and that the winner proceeds to the subsequent round. What is the probability that the highest rated and second-highest rated players will  meet in the final ?</p>

<p>Original Problem Link:  <a href="https://www.quantguide.io/questions/chess-tournament-i">Click here</a></p>

<hr />

<h2 id="solution">Solution</h2>

<p>Before proceeding to the question, let‚Äôs think of the following situation -<br />
Initially, 128 people are divided into 2 groups of 64 people each.<br />
In every round, each group will play within itself (say each guy plays with the guy beside him). How will a group play within itself?</p>

<p>Consider group A with \(A_1, A_2, A_3, A_4, \dots, A_{63}, A_{64}\).<br />
Let‚Äôs say that adjacent people play chess with each other. Then the games will be:</p>

\[(A_1 - A_2), (A_3 - A_4), \dots, (A_{63} - A_{64})\]

<p>From each game,  one person (with the higher skill) will win .<br />
Thus, after the first round, we will have  32 players remaining .</p>

<p>This process will go on until only  one guy remains in each group , and that person will play with the person from another group to decide the  final winner .</p>

<p>Now, try to convince yourself that this model is  exactly the same  as the situation given in the question.<br />
How? ü§î</p>

<ul>
  <li>If the  initial distribution  of people among  Group A and B , and the  arrangement of people within both groups  are all  random , it will consider all possible plays between every player.</li>
  <li>Each  unique initial arrangement corresponds to a unique gameplay .</li>
  <li>Since by  randomizing the initial group allotment , all possible distributions of people in Group A and B are considered, it means  all possible gameplays  are also considered. This exactly models the given problem.</li>
</ul>

<hr />

<h3 id="key-observation">Key Observation</h3>

<p>In our model of the gameplay, the  highest-rated and second-highest-rated player  will  face off against each other   only when they are in different groups initially .</p>

<p>This problem is now much simpler, effectively reducing it to:</p>

<blockquote>
  <p>In how many ways can I arrange 128 people in 2 groups (their position within the group is unique), such that 2 particular people are always in different groups?</p>
</blockquote>

<hr />

<h3 id="solving-the-sub-problem">Solving the Sub-Problem</h3>

<p>First, let‚Äôs allot the highest player and second-highest player to each group.<br />
There are  2 ways  of doing this:</p>
<ul>
  <li>Highest -&gt; Group A, Second-Highest -&gt; Group B</li>
  <li>Highest -&gt; Group B, Second-Highest -&gt; Group A</li>
</ul>

<p>Now, once this is done:</p>
<ul>
  <li>Out of the remaining  126 people , select  63  people for Group A.</li>
  <li>The remaining  63  go to Group B.</li>
  <li>Now, we must  arrange the people within each group itself , thus another  \((64!) \times (64!)\) (one for each group).</li>
</ul>

<p>Our final expression for the  favorable cases  becomes:</p>

\[n(A) = 2 \times \binom{126}{63} \times (64!) \times (64!)\]

<p>where  \(A\) is the event described above.</p>

<hr />

<h3 id="computing-the-probability">Computing the Probability</h3>

<p>To find the probability of this arrangement, we must compute the  total number of possible arrangements .<br />
Clearly, this is  \(128!\) How ü§î ?</p>

<ul>
  <li>Assume a partition after \(P_{64}\)  (representing the end of Group A and the beginning of Group B) exists, to seperate groups A and B.</li>
  <li>We can linearly arrange all 128 people in \(128!\) ways. Thus each combination will represent a unique gameplay.</li>
</ul>

<p>Thus,</p>

\[n(S) = 128!\]

<p>The required probability is:</p>

\[P(A) = \frac{n(A)}{n(S)}\]

<p>Substituting values:</p>

\[P(A) = \frac{2 \times \binom{126}{63} \times (64!)^2}{128!}\]

<p>Expanding the combination formula:</p>

\[\binom{126}{63} = \frac{126!}{63! \times 63!}\]

<p>Thus:</p>

\[P(A) = \frac{2 \times 126! \times (64!)^2}{63! \times 63! \times 128!}\]

<p>Expanding \(128!\) as \(128 \times 127 \times 126!\):</p>

\[P(A) = \frac{2 \times 126! \times 64! \times 64!}{63! \times 63! \times 128 \times 127 \times 126!}\]

<p>Canceling \(126!\):</p>

\[P(A) = \frac{2 \times 64! \times 64!}{63! \times 63! \times 128 \times 127}\]

<p>Using:</p>

\[\frac{64!}{63!} = 64\]

\[P(A) = \frac{2 \times 64 \times 64}{128 \times 127}\]

<p>Simplifying:</p>

\[P(A) = \frac{64}{127}\]

<hr />

<h3 id="final-answer">Final Answer</h3>

\[\boxed{\frac{64}{127}}\]

<h2 id="thus-the-probability-that-the--highest-rated-and-second-highest-rated-players-meet-in-the-final--is--frac64127">Thus, the probability that the  highest-rated and second-highest-rated players meet in the final  is  \(\frac{64}{127}\).</h2>

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Combinatorics" /><category term="Counting Principle" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry><entry><title type="html">Random Angle II</title><link href="http://localhost:4000/probability/statistics/problems/2025/02/23/Random-Angle-II.html" rel="alternate" type="text/html" title="Random Angle II" /><published>2025-02-23T00:00:00+05:30</published><updated>2025-02-23T00:00:00+05:30</updated><id>http://localhost:4000/probability/statistics/problems/2025/02/23/Random-Angle-II</id><content type="html" xml:base="http://localhost:4000/probability/statistics/problems/2025/02/23/Random-Angle-II.html"><![CDATA[<h2 id="problem-statement">Problem Statement</h2>

<p>A right triangle is being formed with legs labeled  A  and  B . The random lengths of legs<br />
 A  and  B  are both IID  Uniform(0,1)  random variables.</p>

<p>Let  Œ∏  be the angle (in radians) opposite to side  A . Find the probability that:</p>

\[P(\theta &gt; \pi/3)\]

<p>Original Problem Link:  <a href="https://www.quantguide.io/questions/random-angle-ii">Click here</a></p>

<hr />

<h2 id="solution">Solution</h2>
<p>Now we must find \(P(\theta &gt; \pi/3)\).</p>

<p>Note that,</p>

\[\tan(\theta) = \frac{A}{B}\]

<p>where  A  and  B  both are IID  Uniform(0,1)  random variables.</p>

<p>For convenience, let‚Äôs fix  B  for now. Then, this problem becomes much simpler. It reduces to:</p>

<blockquote>
  <p>Given  \(\tan(\theta) = A/B\), where  A  is  Uniform(0,1) ,  B  is a given constant,<br />
find \(P(\theta &gt; \pi/3)\).</p>
</blockquote>

<p>Let‚Äôs try and solve this sub-problem:</p>

\[P(\theta &gt; \pi/3) = P(\tan(\theta) &gt; \sqrt{3}) = P(A/B &gt; \sqrt{3}) = P(A &gt; B\sqrt{3})\]

<p>Now, since  A  is a  Uniform(0,1)  random variable, clearly:</p>

\[P(A &gt; x) = \max(0, 1-x)\]

<p>(How? ü§î)</p>
<ul>
  <li>If \(x\) is between  0  and  1 , well and good.</li>
  <li>If \(x &gt; 1\), since  A  cannot be greater than 1, \(P(A &gt; x) = 0\).</li>
  <li>Still confused? Try intuitively finding \(P(A&gt;0)\), \(P(A&gt;1/2)\), and \(P(A&gt;1)\). You will see the essence of the above expression.</li>
  <li>Still confused? Read up on  PDF (Probability Density Function)  and  CDF (Cumulative Density Function) <br />
of the  continuous Uniform distribution .</li>
</ul>

<p>Therefore, for the smaller sub-problem above:</p>

\[P(A &gt; B\sqrt{3}) = 1 - B\sqrt{3}\]

<p>for all  \(1 - B\sqrt{3} \geq 0 \Rightarrow B \leq 1/\sqrt{3}\) .</p>

<p>Essentially, this is equivalent to writing:</p>

\[P(\theta &gt; \pi/3 \mid B) = 1 - B\sqrt{3}\]

<p>Why? ü§î <br />
Because  \(P(\theta &gt; \pi/3 \mid B)\)  represents the probability of \(\theta\) being greater than \(\pi/3\),<br />
 given some B / conditioned on some B .</p>

<p>This is exactly what we calculated above! By fixing  B , we found  \(P(\theta &gt; \pi/3)\) <br />
in terms of some  B , for a given  B .</p>

<p>But of course, as the question states,  B  is also a  Uniform(0,1)  random variable.</p>

<p>We shall now use the  fundamental law of total probability  here.</p>

<hr />

<h3 id="step-2-using-the-law-of-total-probability">Step 2: Using the Law of Total Probability</h3>
<p>Note that we can say:</p>

\[P(\theta &gt; \pi/3) = \sum P(\theta &gt; \pi/3 \mid B) P(B)\]

<p>for all  B .</p>

<p>Now, we must compute  \(P(B)\) .</p>

<p>What exactly does this represent? ü§î</p>

<p>It basically asks:<br />
<em>‚ÄúWhat is the probability of choosing a particular \(B\) from \([0,1]\)?‚Äù</em></p>

<p>Very small, right?</p>

<p>How do we quantify this?  Using calculus!</p>

<p>We can say that the probability of choosing a particular \(B\) from \([0,1]\) is essentially:</p>

\[\frac{dB}{1} = dB\]

<p>where  dB  is a very small term.</p>

<p>Notice that now our summation actually  reduces to a simple integration , due to our usage of<br />
 ‚Äúelemental B‚Äù or ‚ÄúdB‚Äù  to model \(P(B)\).</p>

<p>Ideally, we should vary  B  from  0 to 1 , but note that  B must be ‚â§ 1/‚àö3 ,<br />
otherwise  \(P(\theta &gt; \pi/3 \mid B) = 0\) .</p>

<p>Therefore, we rewrite the above expression as a definite integral:</p>

\[P(\theta &gt; \pi/3) = \int_{0}^{1/\sqrt{3}} (1 - B\sqrt{3}) dB\]

<hr />

<h3 id="step-3-solving-the-integral">Step 3: Solving the Integral</h3>
<p>Expanding the integral:</p>

\[\int_{0}^{1/\sqrt{3}} (1 - B\sqrt{3}) dB\]

<p>We solve separately:</p>

\[\int 1 \, dB = B\]

\[\int B\sqrt{3} \, dB = \frac{\sqrt{3} B^2}{2}\]

<p>Evaluating from  0  to  1/‚àö3 :</p>

\[P(\theta &gt; \pi/3) = \left[ B - \frac{\sqrt{3} B^2}{2} \right]_{0}^{1/\sqrt{3}}\]

<p>Substituting  B = 1/‚àö3 :</p>

\[P(\theta &gt; \pi/3) = \frac{1}{\sqrt{3}} - \frac{\sqrt{3} (1/3)}{2}\]

\[= \frac{1}{\sqrt{3}} - \frac{\sqrt{3}}{6}\]

\[= \frac{2}{2\sqrt{3}} - \frac{1}{2\sqrt{3}}\]

\[= \frac{1}{2\sqrt{3}}\]

<p>Thus,</p>

\[\boxed{P(\theta &gt; \pi/3) = \frac{1}{2\sqrt{3}}}\]

<hr />

<h3 id="conclusion">Conclusion</h3>
<p>Using a combination of  probability concepts, the law of total probability, and calculus ,<br />
we found that the probability of  Œ∏ exceeding œÄ/3  is  1/2‚àö3 .</p>

<p>This problem highlights how fundamental probability techniques can be used to analyze  geometric randomness .</p>

<hr />

<p>üí°  Did you enjoy this problem? Check out more puzzles in the <a href="https://jxtech-s.github.io/problems/">Problems</a> section!</p>]]></content><author><name>JXTech</name></author><category term="Probability" /><category term="Statistics" /><category term="Problems" /><category term="Probability" /><category term="Uniform Distribution" /><category term="Triangle" /><category term="Integration" /><summary type="html"><![CDATA[Problem Statement]]></summary></entry></feed>